{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-kenya",
   "metadata": {},
   "outputs": [],
   "source": [
    "# done done done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "empirical-private",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.nri.com/en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nervous-wednesday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.nri.com//en/knowledge/publication\n",
      "Capital Markets & IT - lakyara\n",
      "Japan's Asset Management Business\n",
      "Financial Services in Japan\n",
      "Special Reports\n",
      "https://www.nri.com/en/knowledge/report/lst?&year=2021\n",
      "US Energy Transition Report\n",
      "Asia and Europe\n",
      "The Coronavirus Pandemic and the Increase of Teleworking in Eight Countries\n",
      "Challenges and Strategies for Making Connected Services Profitable\n",
      "Countering Structural Changes in the Chinese Auto Industry Brought About by Digitalization Through Collaborations Between Governments and IT Platformers\n",
      "Marketability of In-Car Connected Services\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os \n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime,timedelta\n",
    "from datetime import date\n",
    "import re\n",
    "import sys\n",
    "import urllib, urllib.request, urllib.parse\n",
    "import random\n",
    "from scrawl import *\n",
    "    \n",
    "# Date and time\n",
    "start_time = time.time()\n",
    "current_time = datetime.now().strftime(\"%H-%M-%S\")\n",
    "created_on = date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# client_id = sys.argv[1]\n",
    "client_id = '5f69d22ef472d6646f577fa6'  # Europe\n",
    "site = 'nri_com_publication'\n",
    "c = Crawl()  # creating object\n",
    "\n",
    "# create directories to store logs.\n",
    "log_path = c.create_directories(project_path, client_id, site)\n",
    "\n",
    "## creating pdf directories\n",
    "pdf_directory = c.create_pdf_directories(project_path, site)\n",
    "# create image directories\n",
    "image_directory = c.create_image_directories(project_path)\n",
    "\n",
    "# logger\n",
    "logger = log_func(log_path, created_on, current_time)\n",
    "logger.info(\"Process Started ...\\n\")\n",
    "\n",
    "# initialize variables\n",
    "skipped_due_to_headline = 0\n",
    "skipped_due_to_content = 0\n",
    "skipped_due_to_date = 0\n",
    "missing_overall_tonality = 0\n",
    "no_of_data = 0\n",
    "duplicate_data = 0  \n",
    "unable_to_fetch_article_url = 0\n",
    "unable_to_fetch_cat_url = 0\n",
    "unable_to_download_pdf = 0\n",
    "publish_source = 'nri.com'\n",
    "country = 'Japan'\n",
    "language = 'English'\n",
    "images_path = []\n",
    "\n",
    "year = date.today().strftime(\"%Y\")\n",
    "home_page = c.download_page('https://www.nri.com/en')\n",
    "home_page = c.scrap('<ul\\s*class=\"list-category-menu\">(.*?)</div>',home_page)\n",
    "for _ in home_page.split('<a href=')[1:]:  \n",
    "    cat_url = c.scrap('\"(.*?)\"', _)  \n",
    "    if 'blog' in cat_url:\n",
    "        continue\n",
    "    if 'http' not in cat_url:\n",
    "        cat_url = \"https://www.nri.com/\" + cat_url\n",
    "    if 'report' in cat_url:\n",
    "        cat_url = f'https://www.nri.com/en/knowledge/report/lst?&year={year}'\n",
    "    logger.info(f'Fetching cat url  {cat_url}\\n')\n",
    "    cat_page = c.download_page(cat_url)    \n",
    "    if cat_page.startswith('Unable to fetch'):\n",
    "        logger.info(cat_page) \n",
    "        unable_to_fetch_cat_url += 1\n",
    "        continue \n",
    " #   split articles with 2 different condition bec in publication and in reports articles have different different split pattern\n",
    "    if '<a class=\"panel-publications' in cat_page:\n",
    "        split_pattern = '<a class=\"panel-publications'\n",
    "    else:\n",
    "        split_pattern = '<a target=\"_self\"'\n",
    "    for i in cat_page.split(split_pattern)[1:]:\n",
    "        # source_link\n",
    "        source_link = c.scrap('href=\"(.*?)\"', i)\n",
    "        if 'http' not in source_link:\n",
    "            source_link = 'https://www.nri.com' +  source_link\n",
    " \n",
    "        # handle duplicates\n",
    "        source_link_query = {'source_link':source_link}\n",
    "        dic = cl_data.find_one(source_link_query,{'source_link': 1}) \n",
    "        if dic:\n",
    "            duplicate_data += 1\n",
    "            continue\n",
    "\n",
    "        time.sleep(random.randint(1,3))\n",
    "\n",
    "        logger.info(f'Fetching {source_link}\\n')\n",
    "        \n",
    "        page = c.download_page(source_link)   # here the page wil get download\n",
    "        \n",
    "        if page.startswith('Unable to fetch'):     \n",
    "            logger.info(page) # writes error message with error code\n",
    "            unable_to_fetch_article_url += 1\n",
    "            continue    \n",
    "\n",
    "        source_headline = c.scrap('<h1\\s*class=\"heading-h1\">(.*?)<', page)\n",
    "        source_headline = re.sub('&.*?;','',source_headline)\n",
    "       \n",
    "        # skip if headline not found\n",
    "        if not source_headline:\n",
    "            logger.info(f'Skipping due to headline {source_link}\\n')\n",
    "            skipped_due_to_headline += 1\n",
    "            continue\n",
    "            \n",
    "         # Date and time\n",
    "        pub_date, publish_time = '', ''\n",
    "        publish_time = current_time\n",
    "        if 'publication' not in source_link:\n",
    "            try:\n",
    "                date_time_str = c.scrap('<div\\s*class=\"l-day\">.*?<p>(.*?)</p>', page) \n",
    "                date_time_str = re.sub('[^\\w+]', '', date_time_str)  \n",
    "                date_time_obj = datetime.strptime(date_time_str, '%b%d%Y')  \n",
    "                ist_date_time = date_time_obj + timedelta(hours = 2,minutes = 30)  \n",
    "                ist_date_time = ist_date_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                pub_date = ist_date_time[:10]\n",
    "                publish_time = ist_date_time[11:]\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "        else:  \n",
    "            pub_date, publish_time = created_on,current_time\n",
    "#         print(pub_date)\n",
    "#         continue\n",
    "        # skip null date\n",
    "        if not pub_date:\n",
    "            logger.info(f'Skipping due to date {source_link}\\n')            \n",
    "            skipped_due_to_date += 1\n",
    "            continue\n",
    "\n",
    "        # break if date is not today's date\n",
    "#         if pub_date != created_on:\n",
    "#             break    \n",
    "\n",
    "\n",
    "        # source_content         \n",
    "        source_content= c.scrap('<div\\s*class=\"fxb-col-12\">(.*?)</p></p>',page)   \n",
    "        if not source_content:\n",
    "            source_content= c.scrap('<div\\s*class=\"fxb-col-12\">(.*?)<div\\s*class=\"fxb-section\">',page)\n",
    "        source_content = re.sub('&.*?;','',source_content)\n",
    "        source_content = c.strip_html(source_content)  \n",
    "        if not source_content:\n",
    "            logger.info(f'Skipping due to content {source_link}\\n')            \n",
    "            skipped_due_to_content += 1\n",
    "            continue\n",
    "\n",
    "        \n",
    "        journalist =c.scrap(\"'author-name':'(.*?)'\",page)\n",
    "\n",
    "        if not journalist: journalist = 'NA'\n",
    "            \n",
    "        # pdf     \n",
    "        if 'publication' in source_link:\n",
    "            new_source_link = c.scrap('<p\\s*class=\"title\">\\s*<a href=\"(.*?)\"',page)\n",
    "            if 'http' not in new_source_link:\n",
    "                new_source_link = 'https://www.nri.com' + new_source_link\n",
    "            page = c.download_page(new_source_link)\n",
    "        # pdf url\n",
    "        for i in page.split('href=')[1:]:\n",
    "            pdf_url = c.scrap('\"(.*?)\\.pdf',i)\n",
    "            if 'http' not in pdf_url:\n",
    "                pdf_url = 'https://www.nri.com' +pdf_url\n",
    "            if pdf_url:\n",
    "                pdf_name = c.scrap('.*\\/(.*)',pdf_url) +'.pdf'\n",
    "                if 'www.nri.com' in pdf_name:\n",
    "                    continue\n",
    "                pdf_path = f'{pdf_directory}/{pdf_name}' \n",
    "                \n",
    "               # download pdf\n",
    "                pdf = c.download_pdf(pdf_url, pdf_path)\n",
    "                if pdf.startswith('Unable to fetch'):\n",
    "                    logger.info(pdf) # writes error message with error code\n",
    "                    unable_to_download_pdf += 1\n",
    "                    continue\n",
    "\n",
    "\n",
    "        # current date and time 00\n",
    "        harvest_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "        # temp link\n",
    "        temp_link = source_link\n",
    "\n",
    "        # headline and content \n",
    "        headline = source_headline\n",
    "        content = source_content\n",
    "\n",
    "        # overall_tonality\n",
    "        overall_tonality = ''\n",
    "\n",
    "        # word count\n",
    "        word_count = len((source_headline + ' ' + source_content).split())\n",
    "\n",
    "        html_content = ''\n",
    "\n",
    "        # image_urls\n",
    "        image_urls = []\n",
    "    \n",
    "\n",
    "        # storing the above data in a dictionary\n",
    "        clientdata ={\n",
    "                        \"client_master\" : client_id, \n",
    "                        \"articleid\":client_id,\n",
    "                        \"medium\":'Web' ,\n",
    "                        \"searchkeyword\":[],\n",
    "                        \"entityname\" : [] ,\n",
    "                        \"process_flage\":\"1\",\n",
    "                        \"na_flage\":\"0\",\n",
    "                        \"na_reason\":\"\",\n",
    "                        \"qc_by\":\"\",\n",
    "                        \"qc_on\":\"\",\n",
    "                        \"location\":\"\",\n",
    "                        \"spokeperson\":\"\",\n",
    "                        \"quota\":\"\",\n",
    "                        \"overall_topics\":\"\",\n",
    "                        \"person\":\"\",\n",
    "                        \"overall_entites\":\"\",\n",
    "                        \"overall_tonality\": overall_tonality,\n",
    "                        \"overall_wordcount\":word_count,\n",
    "                        \"article_subjectivity\":\"\",\n",
    "                        \"article_summary\":\"\",\n",
    "                        \"pub_date\":pub_date,\n",
    "                        \"publish_time\":publish_time,\n",
    "                        \"harvest_time\":harvest_time,\n",
    "                        \"temp_link\":temp_link,\n",
    "                        \"publish_source\": publish_source,\n",
    "                        \"programme\":'null',\n",
    "                        \"feed_class\":\"News\",\n",
    "                        \"publishing_platform\":\"\",\n",
    "                        \"klout_score\":\"\",\n",
    "                        \"journalist\":journalist,\n",
    "                        \"headline\":headline,\n",
    "                        \"content\":content,\n",
    "                        \"source_headline\":source_headline,\n",
    "                        \"source_content\":source_content,\n",
    "                        \"language\":language,\n",
    "                        \"presence\":'null',\n",
    "                        \"clip_type\":'null',\n",
    "                        \"prog_slot\":'null',\n",
    "                        \"op_ed\":'0',\n",
    "                        \"location_mention\":'',\n",
    "                        \"source_link\":source_link,\n",
    "                        \"author_contact\":'',\n",
    "                        \"author_emailid\":'',\n",
    "                        \"author_url\":'',\n",
    "                        \"city\":'',\n",
    "                        \"state\":'',\n",
    "                        \"country\":country,\n",
    "                        \"source\":publish_source,\n",
    "                        \"foot_fall\":'',\n",
    "                        \"created_on\":created_on,\n",
    "                        \"active\":'1',\n",
    "                        'crawl_flag':2,\n",
    "                        \"images_path\":images_path,\n",
    "                        \"html_content\":html_content,\n",
    "                        \"pdf_url\": pdf_url,\n",
    "                        \"pdf_name\": pdf_name,\n",
    "                        \"pdf_path\":pdf_path\n",
    "                    }\n",
    "#         cl_data.insert_one(clientdata)  \n",
    "        no_of_data += 1\n",
    "logger.info('Iteration complete\\n')   \n",
    "logger.info(f'Number of data: {no_of_data}\\n')\n",
    "logger.info(f'Duplicate data: {duplicate_data}\\n')\n",
    "logger.info(f'Unable to fetch cat url: {unable_to_fetch_cat_url}\\n')\n",
    "logger.info(f'Unable to fetch article url: {unable_to_fetch_article_url}\\n')\n",
    "logger.info(f'Skipped due to headline: {skipped_due_to_headline}\\n')\n",
    "logger.info(f'Skipped due to content: {skipped_due_to_content}\\n')\n",
    "logger.info(f'Skipped due to date: {skipped_due_to_date}\\n')\n",
    "logger.info(f'Unable to download pdf: {unable_to_download_pdf}\\n')\n",
    "logger.info(f'country: {country}\\n')\n",
    "logger.info(f'language: {language}\\n')\n",
    "logger.info(f'Processing finished in {time.time() - start_time} seconds.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-tribute",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
