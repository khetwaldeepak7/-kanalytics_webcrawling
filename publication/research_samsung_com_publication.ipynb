{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mighty-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://research.samsung.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "proud-religious",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_url: https://research.samsung.com/artificial-intelligence\n",
      "https://research.samsung.com/news/Open-Source-Project-for-MPEG-5-EVC-Essential-Video-Coding\n",
      "Open-Source Project for MPEG-5 EVC (Essential Video Coding) | Samsung Research\n",
      "2021-07-08\n",
      "The COVID-19 outbreak has changed our lives and relationships over the past year. We now have no other choice but to communicate more often through the Internet. One of the key technologies for talking via the Internet is, definitely, video compression (coding) technology. However, a very old codec, H.264/AVC, is still the primary technology used in video conference applications, whose standardization was finalized about 20 years ago. Experts had undoubtedly developed a more efficient video codec called HEVC, but it is not dominantly available yet because of its complex license policy or computational complexity issues for video conferences.\n",
      "\n",
      "In June 2021, Samsung Research released an open-source video encoder (XEVE: eXtra-fast Essential Video Encoder, https://github.com/mpeg5/xeve) and decoder (XEVD: eXtra-fast Essential Video Decoder, https://github.com/mpeg5/xevd), which are software implementations of the state-of-the-art video coding standard, MPEG-5 Essential Video Coding (EVC), providing better visual quality for video calls and alleviating the expensive royalty for video codecs.\n",
      "\n",
      "The EVC standard completed by the ISO/IEC Moving Picture Experts Group (MPEG) in April 2020 defines two profiles: (1) the Baseline profile, which is royalty-free as it only consists of technologies that are more than 20 years old, and (2) the Main profile, which contains enhanced tools to improve the compression efficiency. At an equivalent level of visual quality, the Baseline and Main profiles save bit rate by approximately 40% compared to the H.264/AVC and HEVC standards, respectively. For your reference, HEVC saves approximately 40% of the bit rate compared to H.264/AVC.\n",
      "\n",
      "The main purpose of our source code release is to make the MPEG-5 EVC standard more widely and easily used in the industry. For example, the high-performance, commercial-ready, open-source encoder XEVE can be directly deployed to over-the-top (OTT) services without additional development and enable high-quality encoding of video contents. XEVD, a lightweight, open-source decoder, can be directly deployed on embedded devices such as smartphones to play video streams from OTT services. Moreover, XEVE and XEVD can provide improved visual quality and cost-efficient delivery for real-time video conference services, and we believe these services will continue to be popular even after the pandemic.\n",
      "\n",
      "In addition to this effort, Samsung has been striving to adopt the Baseline profile of EVC into the WebRTC standard for real-time video communication on web browsers and mobile applications. Its integration to the WebRTC standard shall prompt better experiences on virtual video communication at a lower cost.\n",
      "https://research.samsung.com/blog/Fixing-overestimation-bias-in-continuous-reinforcement-learning\n",
      "Fixing-overestimation-bias-in-continuous-reinforcement-learning\n",
      "2021-07-01\n",
      "Introduction\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\tIn the last few years, reinforcement learning (RL) has shown excellent results that not so long ago seemed very difficult or even impossible to achieve:\n",
      "\n",
      "\t\t\t\t\t\tAlphaStar beats one of the world’s strongest professional StarCraft players\n",
      "\t\t\t\t\t\tOpenAI five had more than 99% win rate against humans in Dota2\n",
      "\t\t\t\t\t\tAlphaGo defeated Go world champion\n",
      "\n",
      "\t\t\t\t\tMoreover, recent work [1] argues that RL may be a sufficient tool to achieve artificial general intelligence. We also made our contribution to this growing and prospective field.\n",
      "\n",
      "\t\t\t\t\tIn RL, an agent interacts with the environment for multiple steps trying to maximize rewards which are given for the “right” actions or sequences of actions. At each step, an agent observes the current state s of the environment, takes appropriate action a, and in response gets the next state s’ from the environment and the reward r evaluating the performance of the agent. For example, a state could be the position and speed of all joints of a robot, an action — force applied to the joints, and q reward — the movement speed of the robot.\n",
      "\n",
      "\t\t\t\t\tTo assess its performance, an agent learns for each state-action pair an estimate Q(s, a) of how much reward it will get in the future if it takes the action a right now, and then proceeds according to its current policy. It is called Q-function (or state-action value function) and usually is modeled by a neural network. The policy is trained via differentiation through Q-function.\n",
      "\n",
      "\t\t\t\t\tQ-function is usually trained to predict the sum of immediate reward and discounted Q-function in the next state, which is called Temporal Difference learning (TD learning).\n",
      "\n",
      "\t\t\t\t\tOverestimation bias in reinforcement learning\n",
      "\t\t\t\t\tOverestimation bias occurs when estimated values Qθ(s, a) are in general greater than true values Q(s, a), thus the agent overestimates the expected future rewards. Policy seeks these erroneous overestimations and exploits them. It may lead to poor policy performance and propagation of estimation errors through TD learning. Origins of overestimation bias could be described from two points of view.\n",
      "\n",
      "\t\t\t\t\tInformal view.\n",
      "\n",
      "\t\t\t\t\t\t\t1) One wants to recover the true Q-values based on the stochastic samples marked by blue crosses. \n",
      "\t\t\t\t\t\t\t2) Their approximation estimates the true Q-function being based on stochastic samples.\n",
      "\t\t\t\t\t\t\t3) Since the optimization procedure is imprecise, approximation differs from the real Q-function.\n",
      "\t\t\t\t\t\t\t4) The agent optimizes to select the action aapprox with the highest estimate. And when these estimates are erroneously high, the overestimation error occurs. \n",
      "\n",
      "\t\t\t\t\tFormal view. Let us denote the difference between approximation and the true Q-function as additive noise U and assume it has zero mean. By applying Jensen inequality, we can show that maximization of the approximate Q-function leads to overestimation with respect to the true Q-function:\n",
      "\n",
      "\t\t\t\t\tControlling overestimation bias\n",
      "\t\t\t\t\tState-of-the-art algorithms in continuous RL, such as Soft Actor Critic (SAC) [2] and Twin Delayed Deep Deterministic Policy Gradient (TD3) [3], handle these overestimations by training two Q-function approximations and using the minimum over them. This approach is called Clipped Double Q-learning [2]. \n",
      "\n",
      "\t\t\t\t\t\t\t1) One trains two approximations Qθ1 and Qθ1\n",
      "\t\t\t\t\t\t\t2) Uses the minimum of these approximations as the target for training\n",
      "\n",
      "\t\t\t\t\tIf one approximation has a false hill in its landscape, the second approximation often will not have such an exact defect; a minimum of two will be a better estimation. \n",
      "\n",
      "\t\t\t\t\tThis method, however, has one serious drawback — limited flexibility. The required level of overestimation suppression may vary depending on the task, and all one can do is to change the number of networks to take the minimum of, and three networks usually work worse than two. However, one may want to get an intermediate level of overestimation control between a single network and two networks, or between two and three ones. Our method, Truncated Quantile Critics (TQC)[4], does not have this limitation.\n",
      "\n",
      "\t\t\t\t\tTruncated Quantile Critics - TQC\n",
      "\t\t\t\t\tOur work [4] proposes another way to alleviate overestimation bias. We use already known distributional critics [5]: instead of estimating an average return given state and action, a distributional critic estimates the whole distribution of returns. It does that by having multiple outputs, which model a uniform grid of quantiles of the return distribution [6]. The mixture of delta functions (atoms) in places of these quantiles model the whole distribution. The average of all atoms is used for policy optimization instead of a single Q-value.\n",
      "\n",
      "\t\t\t\t\t\tfrom  “Implicit Quantile Networks for Distributional Reinforcement Learning”\n",
      "\n",
      "\t\t\t\t\tWe use N different Q-networks, each network outputs M quantiles of approximated distribution. To construct a target for TD-learning, we mix all the quantile outputs, sort them by their values, and truncate the predefined number of d atoms per network from the right tail of the resulting distribution. After that, we multiply the result by discount γ and add an immediate reward.\n",
      "\n",
      "\t\t\t\t\tThe idea here is, if we have an outlier network with inadequately large values, it will be trimmed, and its effect on the overall average value will be reduced. Also, outlier atoms in any of the critic networks are going to be removed from estimation. Interestingly, this procedure provides a better way to solve the overestimation bias problem than the previous one, which is demonstrated by experimental results. Moreover, the use of distributional critics boosts its performance.\n",
      "\n",
      "\t\t\t\t\tResults\n",
      "\t\t\t\t\tUltimately, our method has several contributions to the field:\n",
      "\n",
      "\t\t\t\t\t\t\tFor the first time, we incorporate the uncertainty of return into the overestimation control\n",
      "\t\t\t\t\t\t\tWe decouple overestimation control and critics’ ensembling\n",
      "\t\t\t\t\t\t\tOur work ensembles distributional critics in a novel way\n",
      "\n",
      "\t\t\t\t\tOur method achieves state-of-the-art results on the popular benchmark suite MuJoCo [7]. This benchmark suite consists of multiple locomotion tasks with 2D and 3D agents. Both SAC and TD3 methods have a minimum of 2 Q-functions as their overestimation alleviation technique. TrulyPPO is a variation of on-policy method PPO.\n",
      "\n",
      "\t\t\t\t\tHere, a comparison of our learned agents and previous SOTA on the Humanoid-v3 environment is shown. As one can observe, 25% improvement in score translates into two times speed increase. A longer video can be viewed here.\n",
      "\n",
      "\t\t\t\t\tReinforcement learning research is as active as never before. We hope our paper encourages more work on specific problems that continuous Q-learning faces.\n",
      "\n",
      "\t\t\t\t\t\tReference\n",
      "\t\t\t\t\t\t[1] Silver, David, et al. \"Reward Is Enough.\" Artificial Intelligence (2021): 103535.\n",
      "\t\t\t\t\t\t[2] Fujimoto, Scott, Herke Hoof, and David Meger. \"Addressing function approximation error in actor-critic methods.\" International Conference on Machine Learning. PMLR, 2018.\n",
      "\t\t\t\t\t\t[3] Haarnoja, Tuomas, et al. \"Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor.\" International Conference on Machine Learning. PMLR, 2018.\n",
      "\t\t\t\t\t\t[4] Kuznetsov, Arsenii, et al. \"Controlling overestimation bias with truncated mixture of continuous distributional quantile critics.\" International Conference on Machine Learning. PMLR, 2020.\n",
      "\t\t\t\t\t\t[5] Bellemare, Marc G., Will Dabney, and Rémi Munos. \"A distributional perspective on reinforcement learning.\" International Conference on Machine Learning. PMLR, 2017.\n",
      "\t\t\t\t\t\t[6] Dabney, Will, et al. \"Distributional reinforcement learning with quantile regression.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 32. No. 1. 2018.\n",
      "\t\t\t\t\t\t[7] Todorov, Emanuel, Tom Erez, and Yuval Tassa. \"MuJoCo: A physics engine for model-based control.\" 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, 2012.\n",
      "\t\t\t\t\t\tPublication URL: http://proceedings.mlr.press/v119/kuznetsov20a/kuznetsov20a.pdf\n",
      "https://research.samsung.com/blog/Learning-to-Align-Temporal-Sequences\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning-to-Align-Temporal-Sequences\n",
      "2021-06-21\n",
      "Introduction\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\tTemporal sequences (e.g., videos) are an appealing data source as they provide a rich source of information and additional constraints to leverage in learning. By far the main focus on temporal sequence analysis in computer vision has been on learning representations (i.e., compact abstractions of the input data) targeting high-level distinctions between signals (e.g., action classification, “What action is present in the video?”).  Alternatively, there is work that seek a finer-grained understanding of sequences (e.g., “What particular phase of the action is performed”) but rely on fully-supervised methods, where labels are attached to each element of a sequence.  Acquiring such labels for training at large-scale is a highly laborious, expensive process.\n",
      "\n",
      "\t\t\t\t\tIn this blog, we present our recent work [1] published at CVPR 2021, which reduces the amount of labeled training data needed for learning useful representations.  We cast the training problem as one of learning to globally align temporal sequences.  Here, an alignment amounts to identifying corresponding elements between the two sequences while enforcing that the matches follow the temporal orderings of the signals; see Figure 1 for an illustration.\n",
      "\n",
      "\t\t\t\t\t\tFigure 1. Alignment as a proxy task for representation learning. We introduce a representation learning approach based on (globally) aligning pairs of temporal sequences (e.g., video) depicting the same process (e.g., human action). Our training objective is to learn an element-wise mapping of the high-dimensional data to a low-dimensional one (termed the embedding space) that supports the alignment process. For example, here we illustrate the alignment (denoted by black dashed lines) in the embedding space between videos of the same human action (i.e., tennis forehand) containing significant variations in their appearances and dynamics. Empirically, we show that our learned embeddings are sensitive to both human pose and fine-grained temporal distinctions, while being invariant to appearance, camera viewpoint, and background.\n",
      "\n",
      "\t\t\t\t\tSequence Alignment as a Proxy Task for Representation Learning\n",
      "\t\t\t\t\tA key aspect of our work is an extension of the classical dynamic time warping (DTW) algorithm [2].  DTW is a standard algorithm for measuring the similarities between temporal sequences that are not synchronized, e.g., signals may be dilated or translated with respect to each other.  To avoid the combinatorial explosion in the matching problem, standard DTW uses dynamic programming to efficiently find the optimal alignment between sequences under certain constraints, e.g., the matches must respect the time ordering of the signals.  In our work [1], we introduce a DTW-based training loss to guide the learning of elementwise representations that are distinctive to support sequence alignment.\n",
      "\n",
      "\t\t\t\t\tMore specifically, we propose a probabilistic path finding view of DTW that encompasses the following three key features.\n",
      "\n",
      "\t\t\t\t\t\t\tClassical DTW cannot be used as a training loss because it contains components that are not differentiable, notably the min operator.  We introduce a differentiable smoothMin operator that effectively selects each successive path extension, and show that this operator has a contrastive effect across paths which improves learning.\n",
      "\t\t\t\t\t\t\tThe pairwise embedding similarities that form our cost function are also defined as probabilities, using the softmax operator. Optimizing our loss is shown to correspond to finding the maximum probability of any feasible alignment between paired sequences. The softmax operator over element pairs also provides a contrastive component which we show is crucial to prevent the model from learning trivial embeddings.\n",
      "\t\t\t\t\t\t\tAs an additional supervisory signal, our probabilistic framework admits a straightforward global cycle-consistency loss that matches the alignments recovered through a cycle of sequence pairings.\n",
      "\n",
      "\t\t\t\t\tCollectively, our method takes into account long-term temporal information that allows us to learn temporally distinctive embeddings that support fine-grained temporal distinctions (e.g., human pose), while being largely unaffected to unimportant aspects, such as camera viewpoint, background, and appearance. Figure 2 provides an illustrative technical overview of our alignment approach to representation learning.\n",
      "\n",
      "\t\t\t\t\t\tFigure 2. Summary of our alignment process.Our sequence alignment approach to representation learning begins by encoding each element comprising our sequences (e.g., image frames) using a trainable framewise backbone encoder plus embedding network, ϕ(·), yielding two sequences of embeddings, X and Y. The cost of matching these two sequences is expressed as negative log probabilities and consists of two parts: (i) alignment losses, smoothDTW(·, ·), from X to Y and Y to X based on the cumulative cost along the optimal respective paths and (ii) a global cycle consistency loss that verifies the correspondences computed between each ordered pair of sequences, where · denotes matrix multiplication and I_(M ×M) is the square identity matrix. Note, our alignment cost smoothDTW(·, ·) is not symmetric in its two arguments (due to the asymmetric pairwise matching cost. Higher intensities in the cells comprising the accumulated cost matrices indicate lower values.\n",
      "\n",
      "\t\t\t\t\tResults and Broader Impact\n",
      "\t\t\t\t\tWe evaluated the efficacy of our learned embeddings on challenging temporal fine-grained tasks, thereby going beyond traditional clip-level recognition tasks.  Our approach yields state-of-the-art results on tasks such as action phase classification and video synchronization.  Detailed results are provided in our paper.\n",
      "\n",
      "\t\t\t\t\tThe ability to temporally align sequences can support a variety of downstream tasks including:\n",
      "\n",
      "\t\t\t\t\t\tVideo synchronization could be useful for coaching (comparing a user's motion with an instructor's video), or video editing (e.g., generating synchronized split frame videos).↓\n",
      "\t\t\t\t\t\tFine-grained retrieval can use a video query, or perhaps a language query.  We could support, \"Show me when the gymnast pushes off the horse.\"  This would involve having such temporal descriptions added to one example video that would be used for alignment.\n",
      "\t\t\t\t\t\tAudio queries could assist with timing of events such as selecting frames at which a tennis player hits a ball.\n",
      "\t\t\t\t\t\tIt is feasible to search for audio intervals that match a query image or video clip.\n",
      "\t\t\t\t\t\tA generalization is to embed and audio-visual clip and use the combined signal for improving the temporal alignment signal.\n",
      "\n",
      "\t\t\t\t\tVideo 1 provides examples of several downstream applications.\n",
      "\n",
      "\t\t\t\t\t\tVideo 1. Example downstream applications enabled by our alignment loss.\n",
      "\n",
      "\t\t\t\t\tConclusion\n",
      "\t\t\t\t\tIn summary, this work introduced a novel weakly supervised method for representation learning relying on sequence alignment as a supervisory signal and taking a probabilistic\n",
      "view in tackling this problem. We evaluate our learned representation on tasks requiring fine-grained temporal distinctions and show that we establish a new state of the art. In addition, we present various applications, thereby opening up new avenues for future investigations grounded on our sequence alignment approach.\n",
      "\n",
      "\t\t\t\t\t\tReference\n",
      "\t\t\t\t\t\t[1] Isma Hadji, Konstantinos G. Derpanis, and Allan D. Jepson, Representation Learning via Global Temporal Alignment and Cycle-Consistency, CVPR, 2021.\n",
      "\t\t\t\t\t\t[2] Hiroaki Sakoe and Seibi Chiba. Dynamic programming algorithm optimization for spoken word recognition. TASSP, 26(1):43–49, 1978.\n",
      "\t\t\t\t\t\tPublication URL: https://arxiv.org/abs/2105.05217\n",
      "https://research.samsung.com/news/SRC-B-Won-the-1st-Place-in-CVPR-NAS-2021-Competition\n",
      "SRC-B Won the 1st Place in CVPR-NAS 2021 Competition | Samsung Research\n",
      "2021-06-18\n",
      "The competition hosted by the 2021 Conference on Computer Vision and Pattern Recognition – Neural Architecture Search (CVPR21-NAS) has a wide influence in the world. As one of the research hotspots of artificial intelligence (AI), NAS technology has been widely concerned in recent years. Thus, as a part of the CVPR21-NAS workshop, its competition has a high value in the NAS community.\n",
      "\n",
      "Samsung RD Institute China – Beijing (SRC-B) won first place in one session this year. CVPR21-NAS Unseen Data Track has designed the task to evaluate NAS algorithms over unseen novel tasks and datasets to show how well NAS algorithms can work “out-of-the-box” with little-to-no time for tuning. For the competition, participants were requested to produce a NAS algorithm that, when given a dataset, produces a well-performing, robust neural architecture.\n",
      "\n",
      "The team from SRC-B applied a probabilistic sampling-based NAS method on a residual neural network (ResNet)-based Supernet. The search space includes the selection of channel number, layer number, image resolution, and augmentation policy. Moreover, it is worth mentioning that the final score of SRC-B’s approach is 44%, which is higher than the rest of the participants. SRC-B will continue to optimize this method and look forward to its successful application in Samsungs commercial on-device model in the future.\n",
      "\n",
      "Furthermore, the CVPR21-NAS Track 1: SuperNet attracted 327 teams to participate including Tsinghua University, Chinese Academy of Sciences and Hikvision. SRC-B won third place on this track. Based on the accumulation of related technology experience from the project, SRC-B proposed a novel approach that reduces the sharing degree between different sub-networks, seeks the balance between mutual promotion and influence among subnetworks, and uses training skills to improve the final result. In the future, SRC-B will try to improve the performance of commercial models, as well as the automation of model design and deployment.\n",
      "cat_url: https://research.samsung.com/next-generation-communications\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://research.samsung.com/news/Samsung-Researchers-elected-to-lead-UWB-Technical-Standards-at-FiRa-Consortium\n",
      "Samsung Researchers elected to lead UWB Technical Standards at FiRa Consortium | Samsung Research\n",
      "2021-07-07\n",
      "Samsung Research is pleased to announce that several of its’ researchers have been elected as chairs to lead the next-generation ultra-wideband (UWB) standards for two-year term at FiRa Consortium.\n",
      "\n",
      "Karthik Srinivasa Gopalan, at Samsung R&D Institute India - Bangalore, was re-elected as co-chair of the Technical Working Group, and he will continue leading to deliver technical specifications for the UWB interoperability. Karthik has more than 20 years of experience and has worked extensively in the areas of research, development and standardization in peer-to-peer, contents recommendations, UMTS, Wi-Fi and UWB systems.\n",
      "\n",
      "Clint Chaplin, at Samsung Research America, was also re-elected as co-chair of the Compliance & Certification Working Group, and he will continue to lead the first FiRa Certification Program launching this year. Clint has more than 20 years of experience in connectivity standards, and has shown strong leadership as chairman or Board member in many standards organizations such as Wi-Fi Alliance, IEEE, WiMedia Alliance, NFC, and so on.\n",
      "\n",
      "In addition, Jieun Keum, at Samsung Research, was elected as chair of D2D Task Group, which was newly formed to define specifications for multiple services between two UWB devices such as tap-less payment, directional control of smart home devices and nearby sharing. Jieun brings around 20 years to research and standardization, and has successfully driven standardizations in leadership positions at many other organizations such as OCF (Open Connectivity Foundation), oneM2M and OIPF (Open IPTV Forum).\n",
      "\n",
      "“These election outcomes reflect the strong technical leadership that Samsung has demonstrated in developing UWB standards and driving interoperable ecosystem.” said VP Jin-kyu Han, Head of Standards Research Team at Samsung Research.\n",
      "\n",
      "\tSamsung is a founding member of the FiRa Consortium, which is a member-driven organization dedicated to the development and widespread adoption of seamless user experiences using the secured fine ranging and positioning capabilities of ultra-wideband (UWB) technologies. FiRa Consortium currently has about 70 members ensuring an interoperable UWB ecosystem across chipset, device and service infrastructure. To learn more about the FiRa Consortium, visit www.firaconsortium.org.\n",
      "\n",
      "\tKarthik Srinivasa Gopalan / Clint Chaplin / Jieun Keum\n",
      "https://research.samsung.com/blog/Looking-back-at-5G-to-build-future-6G-in-ITU-R\n",
      "Looking-back-at-5G-to-build-future-6G-in-ITU-R\n",
      "2021-06-22\n",
      "Land and structural drawings required to construct a building\n",
      "\n",
      "\t\t\t\t\tWhat is the most critical element when you construct a building? Both land and a structural drawing would be the most important. If we are comparing mobile communications to buildings, spectrum is the land, and technical standards are the structural drawings.\n",
      "\n",
      "\t\t\t\t\tThe ITU-R1 is the initial place to build a new generation of mobile communications such as 5G and 6G by describing a global vision. In case of 5G, ITU-R developed the 5G Vision  in 2015. To realize the 5G Vision, ITU-R worked hard to find the right land for 5G at WRC-19.  And this 5G Vision facilitated the mobile industry in developing 5G technical specifications. ITU-R completed the structural drawing of 5G in 2020 by approving the technical specifications developed by external standard development organizations such as 3GPP.\n",
      "\n",
      "\t\t\t\t\tIn this article, we would like to look back on our past 10 years’ experience of what and how Samsung’s global spectrum team, including ourselves, have been engaged within ITU-R/WRC in activities of spectrum and technical standards as important elements to construct a building called 5G (IMT-2020 ). Also, towards the end, we would like to briefly sketch 6G on undeveloped land. Samsung’s global spectrum team consists of experts in Korea, Brazil, China, India, UK/Europe, and the USA.\n",
      "\n",
      "\t\t\t\t\tSpectrum for 5G\n",
      "\n",
      "\t\t\t\t\t5G spectrum is mainly divided into two parts, namely, sub 6 GHz such as the 3.5 GHz band and high frequencies called mmWave bands. Existing sub 6 GHz bands for 5G were identified through previous WRCs. However, mmWave bands have never been discussed for mobile communication usage in ITU-R before 2012.\n",
      "\n",
      "\t\t\t\t\tThe time now goes back to 2012.\n",
      "\n",
      "\t\t\t\t\tIn 2012, Samsung Research was accelerating the development of 5G technologies.  In addition, at an ITU-R meeting in July 2012, we submitted a proposal to use mmWave bands for mobile communications. As expected, most meeting attendees were negative about the mobile usage of these bands. However, by continuously showing the feasibility of mmWave mobile technologies, interest has begun to emerge within the ITU-R members. Finally, a consensus was formed in the direction of creating opportunities to identify high frequency bands for IMT at WRC-19.\t\t\n",
      "\n",
      "\t\t\t\t\tFor the IMT identification at WRC-19, the first step was to set up an agenda item of WRC-19 at the previous WRC, i.e., WRC-15, which needed unanimous supports from major administrations. Prior to WRC-15, Samsung’s global spectrum team made huge efforts to persuade major administrations. Thanks to these efforts, most administrations agreed to set it up at WRC-15. The next step was the selection of candidate bands. After some twists and turns, bands that are not the best, but the second best, were chosen as candidate bands for a WRC-19 agenda item at WRC-15, which was Samsung’s first achievement to lead global mobile spectrum discussion and set up an agenda item of WRC. This achievement could be regarded that Samsung became the 5G industry frontier.\n",
      "\n",
      "\t\t\t\t\tFrom WRC-15 to WRC-19, an invisible battle to secure frequency bands continued between opposing camps. It was a race between an incumbent camp who tried to prevent or restrict the use of the bands, already allocated for other services, by IMT and an entering camp who wanted to use those bands for IMT. There are lots of ‘behind the scenes’ stories to talk about, but in any case, we were pleased to make great achievements in identifying mmWave bands including the 26 GHz band for IMT. At long last, 5G got a new land in high frequency band.\n",
      "\n",
      "\t\t\t\t\t\tSome of the Samsung Spectrum Team at the 2019 World Radio Conference\t\t\t\n",
      "\n",
      "\t\t\t\t\tTechnical standardization for 5G\n",
      "\n",
      "\t\t\t\t\tThe land for 5G has been secured. Now, let's look back on how structural drawings were developed to construct a building.\n",
      "\n",
      "\t\t\t\t\tFrom February 2016 to November 2020, the development of 5G technical standardization was carried out, following the ITU-R 5G standardization process depicted in the figure below.\n",
      "\n",
      "\t\t\t\t\t\tITU-R IMT standardization process\t\t\t\n",
      "\n",
      "\t\t\t\t\tFirstly, ITU-R defined technical performance requirements to realize the 5G Vision,2 which provides a global direction and roadmap for the technology, service, frequency, and commercialization. In parallel, the methodology to evaluate candidate technologies was also developed from 2016 to 2017.\n",
      "\n",
      "\t\t\t\t\tIn this stage of defining requirements and evaluation methodology, among administrations and individual industry members, a fierce neck-and-neck race took place to reflect their requirements and evaluation methodologies into ITU-R documents. In our case, as a pioneer of mmWave technology, mmWave-related elements had to be included as a mandate in the requirements and evaluation methodology. It was indeed a difficult task for us since some administrations and industry members did not have confidence on 5G mmWave at that time. However, having overcome not only the competition within mobile industries but also the competition against other industries such as satellite and fixed wireless services, through numerous persuasion and technical explanation to administrations and industries, our proposals were finally adopted in those documents.\n",
      "\n",
      "\t\t\t\t\tOutside ITU-R, external standard development organizations such as 3GPP developed 5G technical specifications, referring to the ITU-R 5G requirements. From October 2017 to July 2019, candidate technologies from external organizations including 3GPP were submitted to ITU-R. The submitted technologies were evaluated to determine whether they fulfill the 5G requirements or not. After the thorough evaluation process, the 5G Recommendation  was finalized in November 2020, and 3GPP technology is honored to become an international standard in law.\n",
      "\n",
      "\t\t\t\t\tTowards 6G\n",
      "\n",
      "\t\t\t\t\tAccording to the GSA report,  163 mobile operators in 64 countries launched their 5G services as of April 2021. We are pleased to see that 5G is coming from the drawings to the solid land and becoming a real mansion. Again looking back on our experience of 5G and even 4G development, it would usually take around a 10-year period to fulfill the entire construction work, from the planning to the building itself. Therefore, with the gradual maturity of 5G, it is time to prepare for the new generation towards 2030. That's 6G!\n",
      "\n",
      "\t\t\t\t\tIn March 2021, ITU-R started to develop the 6G Vision. The 6G Vision is planned to be completed by June 2023, so by this time, the big picture for 6G around 2030 will be designed. HyoungJin Choi, one of us was named as the chairman of 6G Vision group in ITU-R.  It makes us thrilled to lead the development of 6G Vision to prepare a land and a structural drawing for a new building called 6G. It may be also necessary to consider the establishment of an agenda item for 6G spectrum, a broader land that covers low/mid/high and even higher, known as sub-THz, spectrum to construct a skyscraper called 6G, in WRC-23. And we, as the Samsung global spectrum team are on our way towards this new challenge.\n",
      "\n",
      "\t\t\t\t\t\tReference\n",
      "\t\t\t\t\t\t1 The International Telecommunication Union is a specialized agency of the United Nations responsible for all matters related to information and communication technologies. The ITU Radiocommunication sector (ITU-R) is responsible for radiocommunication.\n",
      "\t\t\t\t\t\t2 Recommendation ITU-R M.2083 “IMT Vision – Framework and overall objectives of the future development of IMT for 2020 and beyond”, September 2015\n",
      "\t\t\t\t\t\t3 World radiocommunication conferences (WRC) are held every three to four years to review and revise the Radio Regulations, the international treaty governing the use of the radio-frequency spectrum.\n",
      "\t\t\t\t\t\t4 As defined in Resolution ITU-R 56, the term IMT, International Mobile Telecommunication, is the root name that encompasses all of IMT-2000, IMT-Advanced and IMT-2020 collectively as symmetrically known as 3G, 4G and 5G, respectively.\n",
      "\t\t\t\t\t\t5 Samsung Newsroom: \"Pioneer in 5G Standards, Part 1: Finding the ‘Land of Opportunity’ in 5G Millimeter-Wave,\":https://news.samsung.com/global/pioneer-in-5g-standards-part-1-finding-the-land-of-opportunity-in-5g-millimeter-wave\n",
      "\t\t\t\t\t\t6 Recommendation ITU-R M.2150 : Detailed specifications of the terrestrial radio interfaces of International Mobile Telecommunications-2020 (IMT-2020)\n",
      "\t\t\t\t\t\t7 Networks, Technologies & Spectrum Snapshot: LTE and 5G Market Statistics, GSA, April 2021\n",
      "\t\t\t\t\t\t8 https://news.samsung.com/global/samsung-researcher-named-the-chair-of-itu-r-6g-vision-group\n",
      "https://news.samsung.com/global/samsung-electronics-and-university-of-california-santa-barbara-demonstrate-6g-terahertz-wireless-communication-prototype\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samsung Electronics and University of California Santa Barbara Demonstrate 6G Terahertz Wireless Communication Prototype  Samsung Global Newsroom\n",
      "2021-06-16\n",
      "https://research.samsung.com/blog/Open-Source-Kubernetes-for-the-next-level-of-network-virtualization\n",
      "Open-Source-Kubernetes-for-the-next-level-of-network-virtualization\n",
      "2021-05-27\n",
      "We as Samsung Research have recently presented a research achievement as a global team work with Samsung R&D Institute Poland and Samsung Research America for improving the Kubernetes open source project into the next level of competency in IEEE INFOCOM 2021.\n",
      "\n",
      "\t\t\t\t\tWhat is a background of this research?\n",
      "\t\t\t\t\tContainer technology has revolutionized the way software is being packaged and run. The telecommunications industry, now challenged with the 5G transformation, views containers as the best way to achieve agile infrastructure that offers high throughput and low latency for 5G edge applications. These challenges make optimal scheduling of performance-sensitive workflows a matter of emerging importance.\n",
      "\n",
      "\t\t\t\t\tHow to solve this? Do not worry, we have Kubernetes open source project!\n",
      "\t\t\t\t\tKubernetes is a de-facto standard open source project for container orchestration in IT industries and has been deployed to various cloud solutions including AWS, Google, Microsoft, IBM, VMWare, and so on. It is now in Cloud Native Computing Foundation (CNCF) of Linux Foundation, and is a very dynamic project since over 400 commits are being contributed to it every month. Samsung is also contributing various ideas into this project with a collaboration with community members.\n",
      "\n",
      "\t\t\t\t\tOkay, we have an open source which is free, but is that enough? It is not so simple.\n",
      "\t\t\t\t\tIt is only logical that there are also many new capabilities in the scheduling area. Grabowski and Tyczynski described Kubernetes scheduler and its features available as of Kubernetes v1.16 [1]. It is able to execute the same decision tree policy as Google’s Borg does with the proper configuration [2], but it is not the default choice in Kubernetes, so it requires additional operator’s intervention to activate it. Several improvements have been proposed to Kubernetes scheduler to make it more suitable for public cloud, but they are not considering any network metrics, or examining any inter-application relations and node communication delays, or requiring information about the service function chains that is provided manually, which are all crucial in most of telecommunication use cases in terms of high throughput, low latency orchestration operated in a fully automated manner.\n",
      "\n",
      "\t\t\t\t\tIn addition, the most critical drawback of the existing scheduler enhancement proposals is their incompatibility to the default scheduler of Kubernetes. No matter how excellent the proposed scheduler guarantees, it requires a custom configuration of selectively activating that scheduler for a specific use case – this is a huge blocker in the telecommunication industry in terms of wide deployment of the scheduler solution. When you consider of realizing the better world of technologies with your great idea using open source like Kubernetes, the most important criteria is its generality of deployment in various use cases that in the end should also guarantee compatibility to the existing open source mainstream.\n",
      "\n",
      "\t\t\t\t\tSo what have we been researching and developing for general deployment of the industries?\n",
      "\t\t\t\t\tWe design and implement NetMARKS – Kubernetes scheduler extender that uses information collected by Service Mesh to schedule pods based on current network metrics. Our solution does not conflict with current Kubernetes scheduler plugins or other extenders, and it can be used simultaneously with them to ensure backward compatibility. NetMARKS can automatically discover inter-application relations as well as schedule the application in a way to save the inter-node network bandwidth and to reduce the application response delay by extending the default Kubernetes scheduler including network metrics awareness, to ensure an efficient placement of Service Function Chains (SFCs). In this context, we propose a novel approach to collect network metrics for the scheduler using Istio Service Mesh.\n",
      "\n",
      "\t\t\t\t\tKubernetes for a baseline scheduler, but what is Istio and how it works in NetMARKS?\n",
      "\t\t\t\t\tIstio has a sidecar-based service mesh design as shown in Fig. 1. This architecture assumes that there is an adjacent container, as a sidecar for every application that acts as a proxy and intercepts all the network traffic. Istio uses a powerful proxy named Envoy [3]. It provides multiple functionalities including mutual TLS, L3/L4 traffic filtering, HTTP L7 filtering and routing, telemetry, and advanced load balancing with circuit breaking and automatic retries. To benefit from those features, Envoy Proxy has to be configured properly and has to be provided with certificates. This is done by istiod, which is an essential part of Service Mesh controlplane that governs all Envoy Proxies. Istio is configured using Kubernetes CRD which allows a user to interact with it using Kubernetes objects.\n",
      "\n",
      "\t\t\t\t\t\tFig. 1. An architecture of Istio Service Mesh.\n",
      "\n",
      "\t\t\t\t\tAs Envoy participates in communication between services, it adds some delay to it. Based on [4], Istio generally adds around 3-ms latency for a mesh with 1,000 requests per second across 16 connections. This result can be improved [5] using a Container Network Interface (CNI) plugin, which supports SOCKMAP from the Linux kernel, such as Calico [6] and Cilium [7].\n",
      "\n",
      "\t\t\t\t\tAs the communication is always intercepted by at least one Envoy Proxy, the traffic can be easily traced and monitored. Every Envoy instance can be configured to collect metrics on the traffic that it is passing. These metrics are further collected and stored by Prometheus [8], which can be deployed as a part of Istio control plane. Users can use the data in multiple ways depending on their needs, e.g. for observability and diagnostics using Kiali [9], which visualizes the structure of mesh and presents flows between components.\n",
      "\n",
      "\t\t\t\t\tNetMARKS is intended to be fully backward compatible with kube-scheduler. The most effective way to achieve this is to utilize Kubernetes Scheduler Extension mechanism. Extenders, including NetMARKS, are implemented as separate HTTP services that are contacted by the scheduler whenever a new pod needs to be scheduled. It is assumed that Istio is enabled for all of cluster namespaces, and Prometheus service is deployed as a part of Istio control plane.\n",
      "\n",
      "\t\t\t\t\tNetMARKS uses data collected by the Prometheus to make the scheduling decision. It retrieves two metrics from there: istio_request_bytes_sum and istio_response_bytes_sum, which contain the number of bytes that is transferred in requests and responses respectively. The application entity does not exist in Kubernetes, so it is defined by Istio as a set of pods residing in the same namespace and having the same app label.\n",
      "\n",
      "\t\t\t\t\tBoth requests and responses metrics are summed in (1) to calculate F_(t_1,t_2)^(A,B), which is an average data flow between applications A and B in time period [t_1,t_2 ]  in bytes per second. 〖req〗_t^(A,B) is the number of bytes in requests from application A to application B until t in bytes, and 〖resp〗_t^(B,A)- same for responses from B to A, with respect to 〖req〗_t^(A,B).\n",
      "\n",
      "\t\t\t\t\t\t(1)\n",
      "\n",
      "\t\t\t\t\tMetrics are collected periodically while keeping the average flow, since the start of data collection using (2).\n",
      "\n",
      "\t\t\t\t\t\t(2)\n",
      "\n",
      "\t\t\t\t\tLet F(t_i ) be the current flow at a given time t_i, after expanding F_(t_(i-1),t_i)^(A,B) in (2) with (1). Then, its final numerical model can be derived as follows.\n",
      "\n",
      "\t\t\t\t\t\t(3)\n",
      "\n",
      "\t\t\t\t\tThis data flow metric is used to assess each feasible node that has not been filtered out. The algorithm has two input parameters: a Pod to be scheduled and a Node. Current state of pods assignment to nodes is required to determine where to bind the new Pod, so NetMARKS retrieves this information via Kubernetes API.\n",
      "\n",
      "\t\t\t\t\tOperation \"Get all traffic neighbors of Pod\" selects data flow metrics, where namespace and application label of the Pod match either source or destination of the traffic.\n",
      "\n",
      "\t\t\t\t\tThe result of the algorithm can be understood as a sum of the traffic bandwidths between the Pod communication peers assigned to the Node. To calculate the Score, the algorithm iterates over all the pods that intersect between a set of pods assigned to the Node and a set of Pod communication partners. Then, it adds the flow data to the final result if namespaces are matched.\n",
      "\n",
      "\t\t\t\t\tScheduling example: Consider 4 applications:\n",
      "\n",
      "\t\t\t\t\t\t\t-\tF: farm, producing grain\n",
      "\t\t\t\t\t\t\t-\tW: well, producing water\n",
      "\t\t\t\t\t\t\t-\tP: pig farm, producing pigs, requiring grain and water\n",
      "\t\t\t\t\t\t\t-\tS: slaughter, producing meat, requiring pigs\n",
      "\n",
      "\t\t\t\t\tFig. 2 shows relation and traffic flows between applications. Assuming that F, W, and S are already running on nodes, the algorithm calculates the score in order to place pod with P as follows:\n",
      "\n",
      "\t\t\t\t\t\t\t-\tNode1: State={F},Score=30+50=80\n",
      "\t\t\t\t\t\t\t-\tNode2: State={W},Score=40+70=110\n",
      "\t\t\t\t\t\t\t-\tNode3: State={S},Score=60+100=160\n",
      "\t\t\t\t\t\t\t-\tNode4: State={},Score=0\n",
      "\n",
      "\t\t\t\t\t\tFig. 2. Example of the data flow graph.\n",
      "\n",
      "\t\t\t\t\tThe node3 receives the highest score, because placing pig farm together with slaughter allows to use intra-node communication, the expected volume of which is bigger than others.\n",
      "\n",
      "\t\t\t\t\tHas NetMARKS been validated from rigorous experiments? Yes!!\n",
      "\t\t\t\t\tWe validated our solution using different workloads and processing layouts. Based on our analysis, NetMARKS can reduce application response time up to 37 percent and save up to 50 percent of inter-node bandwidth in a fully automated manner. This significant improvement is crucial to Kubernetes adoption in 5G use cases, especially for multi-access edge computing and machine-to-machine communication.\n",
      "\n",
      "\t\t\t\t\tPublications: https://infocom.info/day/3 ↓\n",
      "\t\t\t\t\t(Day3: Containers and Data Centers session “NetMARKS: Network Metrics-AwaRe Kubernetes Scheduler Powered by Service Mesh”)\n",
      "\n",
      "\t\t\t\t\tWhat is the role of Samsung Open Source Group?\n",
      "\t\t\t\t\tWe have been contributing our idea into various open source projects in technical domains such as telecommunication, IoT, cloud, robotics, artificial intelligence, and so on with various developers across Samsung Electronics and others from various companies and R&D institutes, in order to make the better technical innovation and the bigger ecosystem in an open collaboration. If you are interested in our recent activities, please visit our official website https://opensource.samsung.com/.\n",
      "\n",
      "\t\t\t\t\t\tReference\n",
      "\t\t\t\t\t\t[1] W. T. Marek Grabowski, “Kubernetes scheduling features or how can i make the system do what i want,” in KubeCon + CloudNativeCon Europe, 2017. ↓[Online]. Available: https://www.youtube.com/watch?v=bbPcb2JuJPw\n",
      "\n",
      "\t\t\t\t\t\t[2] A. Verma, L. Pedrosa, M. R. Korupolu, D. Oppenheimer, E. Tune, and J. Wilkes, “Large-scale cluster management at Google with Borg,” in Proceedings of the European Conference on Computer Systems (EuroSys), Bordeaux, France, 2015.\n",
      "\t\t\t\t\t\t[3] “The envoy proxy.” [Online]. Available: https://www.envoyproxy.io/\n",
      "\t\t\t\t\t\t[4] “Istio performance best practices.” [Online]. ↓Available:https://istio.io/latest/blog/2019/performance-best-practices/\n",
      "\t\t\t\t\t\t[5] N. Kapocius, “Performance studies of kubernetes network solutions,” in 2020 IEEE Open Conference of Electrical, Electronic and Information Sciences (eStream), 2020, pp. 1–6.\n",
      "\t\t\t\t\t\t[6] “Project calico.” [Online]. Available: https://www.projectcalico.org/\n",
      "\t\t\t\t\t\t[7] “Project cilium.” [Online]. Available: https://cilium.io/\n",
      "\t\t\t\t\t\t[8] “The prometheus project.” [Online]. Available: https://prometheus.io/\n",
      "\t\t\t\t\t\t[9] “Kiali - service mesh management for istio.” [Online]. Available: https://kiali.io/\n",
      "cat_url: https://research.samsung.com/robot\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://research.samsung.com/blog/Newest-ROS2-Distribution-Galactic-Geochelone-Released\n",
      "Newest-ROS2-Distribution-Galactic-Geochelone-Released\n",
      "2021-05-27\n",
      "May 2021 comes with many new and exciting changes: easing of COVID-19 restrictions in parts of the world, a warm and eventful Kentucky Derby, and the newest release of ROS2, Galactic Geochelone! Galactic is the 7th release of the new Robot Operating System (ROS) 2.0, built on DDS to be the production grade middleware for robotics with all of the amazing tools you came to love in ROS.\n",
      "\n",
      "\t\t\t\t\tROS2 was redesigned from the ground up to handle non-ideal networks found in real-world production environments, communicate between multiple robots in a fleet securely, operate on low-power embedded systems, and leverage the real-time capacity of several different DDS vendors. Galactic is another step forward in its journey; extending existing capabilities and expanding new ones!\n",
      "\n",
      "\t\t\t\t\tReleased on May 23rd, Galactic provides many improvements that have been in the works for the last year. The expected end of life of Galactic will be November 2022, at which time the next LTS distribution of ROS2 will have been released (codenamed “H-Turtle”). Most notably to Galactic, Cyclone DDS is now the default ROS MiddleWare (RMW) vendor. Eclipse Cyclone DDS [1] is a DDS implementation donated to the Eclipse Foundation by ADLINK, building off of their success with Vortex DDS. It has rapidly developed into a community favorite having a great out-of-the-box experience for users and true zero-copy IPC leveraging Eclipse’s Iceoryx project. Other DDS vendors that have Tier 1 support include eProsima’s Fast-DDS [2] and RTI’s Connext DDS [3]. Both of these DDS implementations are still available as binaries for easy install, unit testing support by Open Robotics, and only require setting a single environmental variable to utilize in your system.\n",
      "\n",
      "\t\t\t\t\tThe ROS2 client library and its recursive dependencies have received a Quality Level 1 rating as set out in REP 2004[4], the highest level of quality possible. This translates to high unit and integration test coverage, strict policies regarding the quality of code introduced, process control, and stability. This quality level rating applies not only to rclcpp, but all of its dependencies (e..g rcl, rclc, rmw, etc), marking quality and stability up and down the entire middleware stack. Additionally, ROS2 pushes the default C++ version from C++14 to C++17.\n",
      "\n",
      "\t\t\t\t\tTwo particularly great feature updates occurred in Galactic. It is now possible to externally configure Quality of Service (QoS) settings in ROS2 configuration files and rosbag2 has become substantially more reliable. Rather than statically defining QoS settings in your ROS2 code, you can now opt-in to allow for dynamically overriding these settings at run-time with your parameter file to try different profiles or reconfigure for unique use-cases [5]. rosbag2 was notably “buggy” in Foxy and older distributions. Even in high-stress networking environments, Galactic’s rosbag2 was able to successfully record 100% of messages (closer to 30% for Foxy). Many new features were also added including compression, playback control settings, commandline utilities, and regular expression support for topics to record and playback [6].\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\tThese contributions, and many more, were brought to fruition due to the establishment of the ROS2 Technical Steering Committee (TSC) [7]. The TSC is a group of research and industry leaders who are contributing to the success of ROS2 and the related ecosystem, including Samsung, LG, Microsoft, Amazon, and many others. Samsung Electronics is a member of this TSC, leading the development of cutting-edge localization and mobile robotics technology.\n",
      "\n",
      "\t\t\t\t\t\tTSC Member Companies [8]\n",
      "\n",
      "\t\t\t\t\tThe driving reason so many users choose ROS isn’t just the middleware, timing, logging, and launch systems-- it is the rich ecosystem of robotics capabilities built on ROS. The vast majority of your favorite projects have already been ported to ROS2, many of which have also received significant upgrades. Even now, major projects like Navigation2 (aka Nav2), MoveIt2, and ROS2 Control are receiving significant attention from industry and the community to create next-generation capabilities.\n",
      "\n",
      "\t\t\t\t\tNav2 has had a substantial number of updates from Foxy to Galactic, including 3 new algorithms for planning and control, 7 new behavior tree nodes, and overhauls of external APIs [9]. New Hybrid-A*, A*, and Regulated Pure Pursuit controllers enable Ackermann and legged vehicles to have first-class support in Nav2. A new Theta* planner allows for planning to prioritize straight-line any-angle plans quickly through constrained spaces.\n",
      "\n",
      "\t\t\t\t\tThe default behavior tree of Nav2 was redesigned to be more responsive to preemption calls and execute a minimum set of recovery behaviors to resolve an issue rather than iterate through all possible behaviors. New behavior tree nodes now make it possible to dynamically change planner, controller, or the new ‘goal checker’ plugins from an external application or in unique behavior tree contexts.\n",
      "\n",
      "\t\t\t\t\tFurther, with the introduction of the new Costmap Filters API, we have support for Keepout Zones and Speed Restricted Zones out-of-the-box with tutorials for setup and use [10].\n",
      "\n",
      "\t\t\t\t\tThe new Nav2 Waypoint Follower enables basic robot autonomy by following specific waypoints, stopping at each, and executing the new ‘Task Executor’ plugins to do anything from pausing, to taking a photo, to picking up a box with an attached robot arm. Complementary, a new action API was added enabling Navigate Through Poses behavior. Rather than point-to-point navigation or waypoint following, the Navigate Through Poses action will allow you to specify an arbitrary number of intermediate hard-pose constraints for your robot to navigate through and execute the path without stopping at each via-point. When combined with the Smac Hybrid-A* planner, this creates a kinematically feasible and smooth path between any number of intermediate points.\n",
      "\n",
      "\t\t\t\t\tA full list of new features in Nav2 can be found in [9].\n",
      "\n",
      "\t\t\t\t\tLooking into the future, Spring 2022 we can expect the release of the next LTS release of ROS2, HTurtle. By then, a whole new host of exciting features, capabilities, and algorithms will be available to build amazing robot systems using ROS2.\n",
      "\n",
      "\t\t\t\t\t\tReference\n",
      "\t\t\t\t\t\t[1] https://github.com/eclipse-cyclonedds/cyclonedds\n",
      "\t\t\t\t\t\t[2] https://github.com/eProsima/Fast-DDS\n",
      "\t\t\t\t\t\t[3] https://www.rti.com/products\n",
      "\t\t\t\t\t\t[4] https://ros.org/reps/rep-2004.html#quality-level-1\n",
      "\t\t\t\t\t\t[5] http://design.ros2.org/articles/qos_configurability.html\n",
      "\t\t\t\t\t\t[6] https://github.com/ros2/rosbag2\n",
      "\t\t\t\t\t\t[7] https://docs.ros.org/en/foxy/Governance.html\n",
      "\t\t\t\t\t\t[8] All trademarks are the property of their respective owners.\n",
      "\t\t\t\t\t\t[9] https://navigation.ros.org/migration/Foxy.html\n",
      "\t\t\t\t\t\t[10] https://navigation.ros.org/tutorials/index.html\n",
      "https://news.samsung.com/global/samsung-electronics-obtains-iso-certification-for-personal-care-robot-system-with-gems-hip\n",
      "Samsung Electronics Obtains ISO Certification for Personal Care Robot System With GEMS Hip  Samsung Global Newsroom\n",
      "2020-09-21\n",
      "https://news.samsung.com/global/get-a-glimpse-of-the-next-generation-innovations-on-display-at-samsungs-technology-showcase\n",
      "Get a Glimpse of the Next-generation Innovations on Display at Samsung’s Technology Showcase  Samsung Global Newsroom\n",
      "2019-02-20\n",
      "https://news.samsung.com/global/video-meet-the-samsung-bots-your-companions-of-the-future\n",
      "[Video] Meet the Samsung Bots: Your Companions of the Future  Samsung Global Newsroom\n",
      "2019-01-10\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os \n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime,timedelta\n",
    "from datetime import date\n",
    "import re\n",
    "import sys\n",
    "import urllib, urllib.request, urllib.parse\n",
    "import random\n",
    "from scrawl import *\n",
    "\n",
    "    \n",
    "# Date and time\n",
    "start_time = time.time()\n",
    "current_time = datetime.now().strftime(\"%H-%M-%S\")\n",
    "created_on = date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# client_id = sys.argv[1]\n",
    "client_id = '5f69d22ef472d6646f577fa6'  # Europe\n",
    "site = 'research_samsung_com_publication'\n",
    "c = Crawl()  # creating object\n",
    "site_name = 'Samsung AI Research Center (Republic of Korea)'\n",
    "\n",
    "# Driver Connection      \n",
    "# options = webdriver.ChromeOptions()\n",
    "# options.add_argument('--headless')\n",
    "# browser = webdriver.Chrome(f'{project_path}/chromedriver', options = options )\n",
    "# browser.maximize_window()\n",
    "\n",
    "#firefox\n",
    "# options = Options()\n",
    "# options.headless = True\n",
    "# browser = webdriver.Firefox(options=options)\n",
    "# browser.maximize_window()\n",
    "\n",
    "# create directories to store logs.\n",
    "log_path = c.create_directories(project_path, client_id, site)\n",
    "\n",
    "## creating pdf directories\n",
    "pdf_directory = c.create_pdf_directories(project_path, site)\n",
    "# create image directories\n",
    "image_directory = c.create_image_directories(project_path)\n",
    "\n",
    "# logger\n",
    "logger = log_func(log_path, created_on, current_time)\n",
    "logger.info(\"Process Started ...\\n\")\n",
    "\n",
    "# initialize variables\n",
    "skipped_due_to_headline = 0\n",
    "skipped_due_to_content = 0\n",
    "skipped_due_to_date = 0\n",
    "missing_overall_tonality = 0\n",
    "no_of_data = 0\n",
    "duplicate_data = 0  \n",
    "unable_to_fetch_article_url = 0\n",
    "unable_to_fetch_cat_url = 0\n",
    "unable_to_download_pdf = 0\n",
    "publish_source = 'research.samsung.com'\n",
    "country = 'South Korea'\n",
    "language = 'English'\n",
    "images_path = []\n",
    "\n",
    "foot_fall = c.get_foot_fall(publish_source)\n",
    "\n",
    "home_page = c.download_page('https://research.samsung.com')\n",
    "\n",
    "urls =['https://research.samsung.com/artificial-intelligence',\n",
    "'https://research.samsung.com/next-generation-communications',\n",
    "'https://research.samsung.com/robot']\n",
    "\n",
    "for url in urls:  \n",
    "    cat_url = url  \n",
    "    logger.info(f'Fetching cat url  {cat_url}\\n')\n",
    "    print(\"cat_url:\",cat_url)\n",
    "#     continue\n",
    "    cat_page = c.download_page(cat_url)    \n",
    "    if cat_page.startswith('Unable to fetch'):\n",
    "        logger.info(cat_page) \n",
    "        unable_to_fetch_cat_url += 1\n",
    "        continue \n",
    "\n",
    "    cat_page = c.scrap('<ul\\s*class=\"articles-inner\"(.*?)<footer\\s*id=\"footer\">',cat_page)\n",
    "    for i in cat_page.split('<li')[1:5]:\n",
    "        # source_link\n",
    "        source_link = c.scrap('href=\"(.*?)\"', i)\n",
    "        print(source_link)\n",
    "#         continue\n",
    "\n",
    "        # handle duplicates\n",
    "        source_link_query = {'source_link':source_link}\n",
    "        dic = cl_data.find_one(source_link_query,{'source_link': 1}) \n",
    "        if dic:\n",
    "            duplicate_data += 1\n",
    "            continue\n",
    "\n",
    "        time.sleep(random.randint(1,3))\n",
    "\n",
    "        logger.info(f'Fetching {source_link}\\n')\n",
    "        \n",
    "        page = c.download_page(source_link)   # here the page wil get download\n",
    "        \n",
    "        if page.startswith('Unable to fetch'):     \n",
    "            logger.info(page) # writes error message with error code\n",
    "            unable_to_fetch_article_url += 1\n",
    "            continue   \n",
    "        if 'blog' in source_link:\n",
    "            source_headline = c.scrap('/blog/(.*)',source_link)\n",
    "        else:\n",
    "            source_headline = c.scrap('<title>(.*?)</title>', page)\n",
    "            if not source_headline:\n",
    "                 source_headline = c.scrap('<h1.*?>(.*?)</h1>', page)  \n",
    "        source_headline = re.sub('&.*?;','',source_headline)\n",
    "        print(source_headline)\n",
    "\n",
    "       \n",
    "        # skip if headline not found\n",
    "        if not source_headline:\n",
    "            logger.info(f'Skipping due to headline {source_link}\\n')\n",
    "            skipped_due_to_headline += 1\n",
    "            continue\n",
    "            \n",
    "         # Date and time\n",
    "        pub_date, publish_time = '', ''\n",
    "        publish_time = current_time\n",
    "        try:\n",
    "            date_time_str = c.scrap('class=\"articles-date\".*?>On(.*?)<', i)\n",
    "            date_time_str = re.sub('[^\\w+]', '', date_time_str)  \n",
    "            date_time_obj = datetime.strptime(date_time_str, '%B%d%Y')  \n",
    "            ist_date_time = date_time_obj + timedelta(hours = 0,minutes = 0)  \n",
    "            ist_date_time = ist_date_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            pub_date = ist_date_time[:10]\n",
    "            publish_time = ist_date_time[11:]\n",
    "            print(pub_date)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # skip null date\n",
    "        if not pub_date:\n",
    "            logger.info(f'Skipping due to date {source_link}\\n')            \n",
    "            skipped_due_to_date += 1\n",
    "            continue\n",
    "\n",
    "        # break if date is not today's date\n",
    "#         if pub_date != created_on:\n",
    "#             break    \n",
    "\n",
    "\n",
    "        # source_content         \n",
    "        source_content= c.scrap('<div\\s*class=\"news-con\"><p>(.*?)<footer\\s*id=\"footer\">',page)   \n",
    "        if not source_content:\n",
    "            source_content= c.scrap('div\\s*class=\"text_cont\">(.*?)<div\\s*class=\"fxb-section\">',page)#<div class=\"top_area clearfix\">\n",
    "        if not source_content:\n",
    "            source_content= c.scrap('<div\\s*class=\"news-con\">(.*?)<footer\\s*id=\"footer\">',page)# <div class=\"top_area clearfix\">\n",
    "        if not source_content:\n",
    "            source_content= c.scrap('<div\\s*class=\"news-con\">(.*?)<div\\s*class=\"top_area clearfix\">',page)\n",
    "        source_content = re.sub('<script>(.*?)</script>','',source_content)\n",
    "        source_content = re.sub('&.*?;','',source_content)\n",
    "        source_content = c.strip_html(source_content)  \n",
    "        if not source_content:\n",
    "            logger.info(f'Skipping due to content {source_link}\\n')            \n",
    "            skipped_due_to_content += 1\n",
    "            continue\n",
    "        print(source_content)\n",
    "        continue\n",
    "        \n",
    "        journalist =c.scrap(\"'author-name':'(.*?)'\",page)\n",
    "\n",
    "        if not journalist: journalist = 'NA'\n",
    "\n",
    "\n",
    "        # current date and time 00\n",
    "        harvest_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "        # temp link\n",
    "        temp_link = source_link\n",
    "\n",
    "        # headline and content \n",
    "        headline = source_headline\n",
    "        content = source_content\n",
    "\n",
    "        # overall_tonality\n",
    "        overall_tonality = ''\n",
    "\n",
    "        # word count\n",
    "        word_count = len((source_headline + ' ' + source_content).split())\n",
    "\n",
    "        html_content = ''\n",
    "\n",
    "        # image_urls\n",
    "        image_urls = []\n",
    "    \n",
    "\n",
    "        # storing the above data in a dictionary\n",
    "        clientdata ={\n",
    "                        \"client_master\" : client_id, \n",
    "                        \"articleid\":client_id,\n",
    "                        \"medium\":'Web' ,\n",
    "                        \"searchkeyword\":[],\n",
    "                        \"entityname\" : [] ,\n",
    "                        \"process_flage\":\"1\",\n",
    "                        \"na_flage\":\"0\",\n",
    "                        \"na_reason\":\"\",\n",
    "                        \"qc_by\":\"\",\n",
    "                        \"qc_on\":\"\",\n",
    "                        \"location\":\"\",\n",
    "                        \"spokeperson\":\"\",\n",
    "                        \"quota\":\"\",\n",
    "                        \"overall_topics\":\"\",\n",
    "                        \"person\":\"\",\n",
    "                        \"overall_entites\":\"\",\n",
    "                        \"overall_tonality\": overall_tonality,\n",
    "                        \"overall_wordcount\":word_count,\n",
    "                        \"article_subjectivity\":\"\",\n",
    "                        \"article_summary\":\"\",\n",
    "                        \"pub_date\":pub_date,\n",
    "                        \"publish_time\":publish_time,\n",
    "                        \"harvest_time\":harvest_time,\n",
    "                        \"temp_link\":temp_link,\n",
    "                        \"publish_source\": publish_source,\n",
    "                        \"programme\":'null',\n",
    "                        \"feed_class\":\"News\",\n",
    "                        \"publishing_platform\":\"\",\n",
    "                        \"klout_score\":\"\",\n",
    "                        \"journalist\":journalist,\n",
    "                        \"headline\":headline,\n",
    "                        \"content\":content,\n",
    "                        \"source_headline\":source_headline,\n",
    "                        \"source_content\":source_content,\n",
    "                        \"language\":language,\n",
    "                        \"presence\":'null',\n",
    "                        \"clip_type\":'null',\n",
    "                        \"prog_slot\":'null',\n",
    "                        \"op_ed\":'0',\n",
    "                        \"location_mention\":'',\n",
    "                        \"source_link\":source_link,\n",
    "                        \"author_contact\":'',\n",
    "                        \"author_emailid\":'',\n",
    "                        \"author_url\":'',\n",
    "                        \"city\":'',\n",
    "                        \"state\":'',\n",
    "                        \"country\":country,\n",
    "                        \"source\":publish_source,\n",
    "                        \"foot_fall\":foot_fall,\n",
    "                        \"created_on\":created_on,\n",
    "                        \"active\":'1',\n",
    "                        'crawl_flag':2,\n",
    "                        \"images_path\":images_path,\n",
    "                        \"html_content\":html_content,\n",
    "                        \"pdf_url\": pdf_url,\n",
    "                        \"pdf_name\": pdf_name,\n",
    "                        \"pdf_path\":pdf_path\n",
    "                    }\n",
    "#         cl_data.insert_one(clientdata)  \n",
    "        no_of_data += 1\n",
    "logger.info('Iteration complete\\n')   \n",
    "logger.info(f'Number of data: {no_of_data}\\n')\n",
    "logger.info(f'Duplicate data: {duplicate_data}\\n')\n",
    "logger.info(f'Unable to fetch cat url: {unable_to_fetch_cat_url}\\n')\n",
    "logger.info(f'Unable to fetch article url: {unable_to_fetch_article_url}\\n')\n",
    "logger.info(f'Skipped due to headline: {skipped_due_to_headline}\\n')\n",
    "logger.info(f'Skipped due to content: {skipped_due_to_content}\\n')\n",
    "logger.info(f'Skipped due to date: {skipped_due_to_date}\\n')\n",
    "logger.info(f'Unable to download pdf: {unable_to_download_pdf}\\n')\n",
    "logger.info(f'country: {country}\\n')\n",
    "logger.info(f'language: {language}\\n')\n",
    "logger.info(f'Processing finished in {time.time() - start_time} seconds.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-uganda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fancy-implement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-letter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sustainable-congo",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-animal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-fruit",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
