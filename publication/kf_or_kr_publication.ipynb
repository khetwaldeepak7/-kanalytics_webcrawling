{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-replacement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kf.or.kr/kfEng/main.do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "occasional-mailman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.kf.or.kr/kfEng/na/ntt/selectDgtlInfoList.do?dgtlType=N&mi=2112\n",
      "8\n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: \n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-92ec36bff37e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;31m#         source_link= browser.find_element_by_xpath(\"//*[@id=\\\"cntntsView\\\"]/div[2]/div[2]/div[\"+str(i)+\"]/a[contains(@onclick,'detailView')]\").click()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m         \u001b[0mbutton_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//*[@id=\\\"cntntsView\\\"]/div[2]/div[2]/div[\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"]/a\"\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# esmai wah paticular article ka x path leyga n usko click karwayega\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;31m#         logger.info(f'Fetching {source_link}\\n')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-92ec36bff37e>\u001b[0m in \u001b[0;36mbutton_wait\u001b[1;34m(xpath)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbutton_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m     \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWebDriverWait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbrowser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muntil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisibility_of_element_located\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m     \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sachi-dhara\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\selenium\\webdriver\\support\\wait.py\u001b[0m in \u001b[0;36muntil\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mend_time\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0muntil_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os \n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime,timedelta\n",
    "from datetime import date\n",
    "import re\n",
    "import sys\n",
    "import urllib, urllib.request, urllib.parse\n",
    "import random\n",
    "from scrawl import *\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "from selenium.webdriver.firefox.options import Options\n",
    " \n",
    "# Date and time\n",
    "start_time = time.time()\n",
    "current_time = datetime.now().strftime(\"%H-%M-%S\")\n",
    "created_on = date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# client_id = sys.argv[1]\n",
    "client_id = '5f69d22ef472d6646f577fa6'  # Europe\n",
    "site = 'kf_or_kr_publication'\n",
    "site_name = 'Korea Foundation (Republic of Korea)'\n",
    "c = Crawl()  # creating object\n",
    "\n",
    "# create directories to store logs.\n",
    "log_path = c.create_directories(project_path, client_id, site)\n",
    "\n",
    "# create image directories\n",
    "image_directory = c.create_image_directories(project_path)\n",
    "\n",
    "\n",
    "# Driver Connection      \n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')\n",
    "browser = webdriver.Chrome(f'{project_path}/chromedriver', options = options )\n",
    "browser.maximize_window() \n",
    "    \n",
    "# Firefox driver settings\n",
    "# options = Options()\n",
    "# options.headless = True\n",
    "# browser = webdriver.Firefox(options=options)\n",
    "# browser.maximize_window()\n",
    "    \n",
    "# logger\n",
    "logger = log_func(log_path, created_on, current_time)\n",
    "logger.info(\"Process Started ...\\n\")\n",
    "\n",
    "# initialize variables\n",
    "skipped_due_to_headline = 0\n",
    "skipped_due_to_content = 0\n",
    "skipped_due_to_date = 0\n",
    "missing_overall_tonality = 0\n",
    "no_of_data = 0\n",
    "duplicate_data = 0  \n",
    "unable_to_fetch_article_url = 0\n",
    "unable_to_fetch_cat_url = 0\n",
    "\n",
    "publish_source = 'kf.or.kr'\n",
    "country = 'China'   # check country\n",
    "language = 'English'\n",
    "images_path = []\n",
    "\n",
    "\n",
    "def button_wait(xpath):\n",
    "    e = WebDriverWait(browser, 40).until(ec.visibility_of_element_located((By.XPATH, xpath)))\n",
    "    e.click()\n",
    "    \n",
    "    \n",
    "def text_wait(xpath,text):\n",
    "    e = WebDriverWait(browser, 30).until(ec.visibility_of_element_located((By.XPATH, xpath)))\n",
    "    e.send_keys(text)\n",
    "    \n",
    "    \n",
    "def text_wait_enter(xpath,text):\n",
    "    e = WebDriverWait(browser, 30).until(ec.visibility_of_element_located((By.XPATH, xpath)))\n",
    "    e.send_keys(text)\n",
    "    e.send_keys(Keys.ENTER)\n",
    "    \n",
    "    \n",
    "def get_inner_html(xpath):\n",
    "    try:\n",
    "        e = WebDriverWait(browser, 20).until(ec.visibility_of_element_located((By.XPATH, xpath)))\n",
    "        return e.get_attribute('innerHTML')\n",
    "    except:\n",
    "        return ''\n",
    "    \n",
    "def get_data(xpath):\n",
    "    try:\n",
    "        return WebDriverWait(browser, 20).until(ec.visibility_of_element_located((By.XPATH, xpath))).text\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "home_page = c.download_page('https://www.kf.or.kr/kfEng/main.do?langTy=ENG')\n",
    "home_page = c.scrap('<ul\\s*class=\"dep01\">(.*?)<ul\\s*class=\"dep02\">', home_page)\n",
    "\n",
    "for _ in home_page.split('<li><a href=')[1:2]:  #-1\n",
    "    cat_url = c.scrap('\"(.*?)\"', _)   \n",
    "\n",
    "    if 'http' not in cat_url:\n",
    "        cat_url = 'https://www.kf.or.kr' +  cat_url\n",
    "        \n",
    "    logger.info(f'Fetching cat url  {cat_url}\\n')\n",
    "    print(cat_url)\n",
    "#     continue\n",
    "#-----------------------from here selenium is used---------------------------------------------------------------------,\n",
    "\n",
    "    try:\n",
    "        browser.get(cat_url)\n",
    "    except:\n",
    "        logger.info('Unable to fetch home page\\n')\n",
    "        broswer.quit()\n",
    "        exit()\n",
    "    time.sleep(3)\n",
    "    cat_page = browser.page_source\n",
    "    if cat_page.startswith('Unable to fetch'):\n",
    "        logger.info(cat_page) # writes error message with error code\n",
    "        unable_to_fetch_cat_url += 1\n",
    "        continue    \n",
    "\n",
    "    row_count = len(browser.find_elements_by_xpath('//*[@id=\"cntntsView\"]/div[2]/div[2]/div'))\n",
    "    print(row_count)  \n",
    "    for i in range(1,row_count+1): \n",
    "        \n",
    "#         source_link= browser.find_element_by_xpath(\"//*[@id=\\\"cntntsView\\\"]/div[2]/div[2]/div[\"+str(i)+\"]/a[contains(@onclick,'detailView')]\").click()\n",
    "        button_wait(\"//*[@id=\\\"cntntsView\\\"]/div[2]/div[2]/div[\"+str(i)+\"]/a\")  # esmai wah paticular article ka x path leyga n usko click karwayega\n",
    "        time.sleep(3)\n",
    "#         logger.info(f'Fetching {source_link}\\n')\n",
    "#         source_headline = get_data('//*[@id=\"dgtlModifyForm\"]/div[1]')\n",
    "#         source_content = get_data('//*[@id=\"dgtlModifyForm\"]/div[1]/div')\n",
    "        page = browser.page_source\n",
    "        if page.startswith('Unable to fetch'):     \n",
    "            logger.info(page) # writes error message with error code\n",
    "            unable_to_fetch_article_url += 1\n",
    "            continue    \n",
    "\n",
    "        source_headline = c.scrap('<h3>(.*?)</h3>', page)\n",
    "        source_headline = re.sub('&.*?;','',source_headline)\n",
    "        # skip if headline not found\n",
    "        if not source_headline:\n",
    "#             logger.info(f'Skipping due to headline {source_link}\\n')\n",
    "            skipped_due_to_headline += 1\n",
    "            continue\n",
    "            \n",
    "         # Date and time\n",
    "        pub_date, publish_time = '', ''\n",
    "        publish_time = current_time\n",
    "        try:\n",
    "            date_time_str = c.scrap('<li><strong>Date</strong>(.*?)</li>', page).strip()\n",
    "            date_time_str = re.sub('[^\\w+]', '', date_time_str)  \n",
    "            date_time_obj = datetime.strptime(date_time_str, '%b%d%Y')\n",
    "            ist_date_time = date_time_obj - timedelta(hours = 3,minutes = 30)  \n",
    "            ist_date_time = ist_date_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            pub_date = ist_date_time[:10]\n",
    "            publish_time = ist_date_time[11:]\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # skip null date\n",
    "        if not pub_date:\n",
    "#             logger.info(f'Skipping due to date {source_link}\\n')            \n",
    "            skipped_due_to_date += 1\n",
    "            continue\n",
    "\n",
    "        # break if date is not today's date\n",
    "#         if pub_date != created_on:\n",
    "#             break    \n",
    "\n",
    "\n",
    "        # source_content         \n",
    "        source_content= c.scrap('<div\\s*class=\"bbsV_cont\">(.*?)<div\\s*class=\"sub_container\\s*ac\\s*webzine\">',page)   \n",
    "#         if not source_content:\n",
    "#             source_content= c.scrap('div\\s*class=\"post-data-container\">(.*?)<div\\s*class=\"m-b-',page)\n",
    "\n",
    "        source_content = re.sub('&.*?;','',source_content)\n",
    "        source_content = c.strip_html(source_content)  \n",
    "        if not source_content:\n",
    "#             logger.info(f'Skipping due to content {source_link}\\n')            \n",
    "            skipped_due_to_content += 1\n",
    "            continue\n",
    "\n",
    "        \n",
    "        journalist =c.scrap(\"'author-name':'(.*?)'\",page)\n",
    "\n",
    "        if not journalist: journalist = 'NA'\n",
    "\n",
    "        # current date and time 00\n",
    "        harvest_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "        # temp link\n",
    "        temp_link = source_link\n",
    "\n",
    "        # headline and content \n",
    "        headline = source_headline\n",
    "        content = source_content\n",
    "\n",
    "        # overall_tonality\n",
    "        overall_tonality = ''\n",
    "\n",
    "        # word count\n",
    "        word_count = len((source_headline + ' ' + source_content).split())\n",
    "\n",
    "        html_content = ''\n",
    "\n",
    "        # image_urls\n",
    "        image_urls = []\n",
    "    \n",
    "        # storing the above data in a dictionary\n",
    "        clientdata ={\n",
    "                        \"client_master\" : client_id, \n",
    "                        \"articleid\":client_id,\n",
    "                        \"medium\":'Web' ,\n",
    "                        \"searchkeyword\":[],\n",
    "                        \"entityname\" : [] ,\n",
    "                        \"process_flage\":\"1\",\n",
    "                        \"na_flage\":\"0\",\n",
    "                        \"na_reason\":\"\",\n",
    "                        \"qc_by\":\"\",\n",
    "                        \"qc_on\":\"\",\n",
    "                        \"location\":\"\",\n",
    "                        \"spokeperson\":\"\",\n",
    "                        \"quota\":\"\",\n",
    "                        \"overall_topics\":\"\",\n",
    "                        \"person\":\"\",\n",
    "                        \"overall_entites\":\"\",\n",
    "                        \"overall_tonality\": overall_tonality,\n",
    "                        \"overall_wordcount\":word_count,\n",
    "                        \"article_subjectivity\":\"\",\n",
    "                        \"article_summary\":\"\",\n",
    "                        \"pub_date\":pub_date,\n",
    "                        \"publish_time\":publish_time,\n",
    "                        \"harvest_time\":harvest_time,\n",
    "                        \"temp_link\":temp_link,\n",
    "                        \"publish_source\": publish_source,\n",
    "                        \"programme\":'null',\n",
    "                        \"feed_class\":\"News\",\n",
    "                        \"publishing_platform\":\"\",\n",
    "                        \"klout_score\":\"\",\n",
    "                        \"journalist\":journalist,\n",
    "                        \"headline\":headline,\n",
    "                        \"content\":content,\n",
    "                        \"source_headline\":source_headline,\n",
    "                        \"source_content\":source_content,\n",
    "                        \"language\":language,\n",
    "                        \"presence\":'null',\n",
    "                        \"clip_type\":'null',\n",
    "                        \"prog_slot\":'null',\n",
    "                        \"op_ed\":'0',\n",
    "                        \"location_mention\":'',\n",
    "                        \"source_link\":source_link,\n",
    "                        \"author_contact\":'',\n",
    "                        \"author_emailid\":'',\n",
    "                        \"author_url\":'',\n",
    "                        \"city\":'',\n",
    "                        \"state\":'',\n",
    "                        \"country\":country,\n",
    "                        \"source\":publish_source,\n",
    "                        \"foot_fall\":'',\n",
    "                        \"created_on\":created_on,\n",
    "                        \"active\":'1',\n",
    "                        'crawl_flag':2,\n",
    "                        \"images_path\":images_path,\n",
    "                        \"html_content\":html_content,\n",
    "                        \"pdf_url\": pdf_url,\n",
    "                        \"pdf_name\": pdf_name,\n",
    "                        \"pdf_path\":pdf_path\n",
    "                    }\n",
    "#         cl_data.insert_one(clientdata)  \n",
    "        no_of_data += 1\n",
    "\n",
    "\n",
    "logger.info('Iteration complete\\n')   \n",
    "logger.info(f'Number of data: {no_of_data}\\n')\n",
    "logger.info(f'Duplicate data: {duplicate_data}\\n')\n",
    "logger.info(f'Unable to fetch cat url: {unable_to_fetch_cat_url}\\n')\n",
    "logger.info(f'Unable to fetch article url: {unable_to_fetch_article_url}\\n')\n",
    "logger.info(f'Skipped due to headline: {skipped_due_to_headline}\\n')\n",
    "logger.info(f'Skipped due to content: {skipped_due_to_content}\\n')\n",
    "logger.info(f'Skipped due to date: {skipped_due_to_date}\\n')\n",
    "logger.info(f'country: {country}\\n')\n",
    "logger.info(f'language: {language}\\n')\n",
    "logger.info(f'Processing finished in {time.time() - start_time} seconds.\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-remove",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "contained-writer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "continuous-player",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jfdjv'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "pressed-invitation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-token",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-combining",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
