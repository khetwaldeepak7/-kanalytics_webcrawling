{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "complex-strike",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time error\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'user_page' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1ba6eeb9ab38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"time error\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0muser_page\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unable to fetch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_page\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# writes error message with error code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[0mno_of_not_working_queries\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'user_page' is not defined"
     ]
    }
   ],
   "source": [
    "from scrawl import *\n",
    "import random\n",
    "import json\n",
    "import os \n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime,timedelta\n",
    "from datetime import date\n",
    "import re\n",
    "import sys\n",
    "import urllib, urllib.request, urllib.parse\n",
    "\n",
    "\n",
    "c = Crawl() # Creating object\n",
    "\n",
    "# Creating list of proxies\n",
    "proxy_col = dashboard['proxies']\n",
    "proxy = proxy_col.find({'country':'China'})\n",
    "proxy_list = list(map(lambda x:x['ip'],list(proxy)))\n",
    "\n",
    "def get_proxy():\n",
    "    \n",
    "    return {'http': random.choice(proxy_list)}\n",
    "\n",
    "\n",
    "def download_image(image_url,image_path):\n",
    "\n",
    "    time.sleep(random.randint(1,3))\n",
    "    try:\n",
    "        r = requests.get(image_url,proxies=get_proxy(),timeout=120)\n",
    "    #         r = requests.get(image_url,timeout=120)\n",
    "        response_code = r.status_code\n",
    "        if response_code != 200:\n",
    "            return f'Unable to fetch image {image_url} Error code: {r.status_code}\\n'\n",
    "            # print(f'Unable to fetch image {image_url} Error code: {r.status_code}')\n",
    "        else:\n",
    "            r = r.content\n",
    "            with open(image_path, 'wb') as f:\n",
    "                f.write(r)\n",
    "    except:\n",
    "        return f'Unable to fetch image {image_url} Unknown error\\n'\n",
    "        print(f'Unable to fetch image {image_url} Unknown error\\n')\n",
    "\n",
    "    \n",
    "# Date and time\n",
    "start_time = time.time()\n",
    "current_time = datetime.now().strftime(\"%H-%M-%S\")\n",
    "created_on = date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# client_id = sys.argv[1]\n",
    "client_id = '5eb16c2db378671cf746ebb8'  \n",
    "site = 's_weibo_com_user'\n",
    "cl_data = dashboard['core_weibo']\n",
    "\n",
    "# create directories to store logs.\n",
    "log_path = c.create_directories(project_path, client_id, site)\n",
    "\n",
    "# create image directories\n",
    "image_directory = c.create_image_directories(project_path)\n",
    "\n",
    "# logger\n",
    "logger = log_func(log_path, created_on, current_time)\n",
    "logger.info(\"Process Started ...\\n\")\n",
    "\n",
    "# initialize variables\n",
    "skipped_due_to_username = 0\n",
    "skipped_due_to_headline = 0\n",
    "skipped_due_to_content = 0\n",
    "skipped_due_to_date = 0\n",
    "missing_overall_tonality = 0\n",
    "no_of_data = 0\n",
    "duplicate_data = 0  \n",
    "unable_to_fetch_url = 0\n",
    "unable_to_download_image = 0\n",
    "publish_source = 's.weibo.com'\n",
    "country = 'China'\n",
    "language = 'Chinese'\n",
    "cnt = 0\n",
    "publish_time = '00:00:00'\n",
    "pub_date = created_on \n",
    "# Hence we will concate date(which is in a sentence) in the source content.\n",
    "no_of_not_working_queries = 0\n",
    "headers = {\n",
    "    'authority': 'weibo.com',\n",
    "    'cache-control': 'max-age=0',\n",
    "    'sec-ch-ua': '^\\\\^',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'upgrade-insecure-requests': '1',\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36',\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,/;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "    'sec-fetch-site': 'same-origin',\n",
    "    'sec-fetch-mode': 'navigate',\n",
    "    'sec-fetch-user': '?1',\n",
    "    'sec-fetch-dest': 'document',\n",
    "    'accept-language': 'en-IN,en-GB;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "    'cookie': 'SINAGLOBAL=764815322341.5566.1622097283265; SUB=2AkMXj8zTf8NxqwJRmP0RzmrjaY1yyg3EieKh0z0IJRMxHRl-yT92qmgntRB6PA_iPI199P4zlRz9zonVc5W23plzUH7V; SUBP=0033WrSXqPxfM72-Ws9jqgMF55529P9D9W55o9Nf.NuDNjNQuIS8pJY; _s_tentry=-; Apache=3847225399074.1636.1624690011593; ULV=1624690011604:5:4:4:3847225399074.1636.1624690011593:1624608998989',\n",
    "}\n",
    "\n",
    "user_links = ['https://weibo.com/globaltimescn?refer_flag=1001030103_&ssl_rnd=1623643790.2876',\n",
    "             'https://weibo.com/newsxh?refer_flag=1001030103_&is_all=1&ssl_rnd=1625039615.9147',\n",
    "             'https://weibo.com/u/7547570847?ssl_rnd=1625044773.0251&is_all=1',\n",
    "             'https://weibo.com/hebgqt?refer_flag=1001030103_&is_all=1&is_all=1&ssl_rnd=1625039615.9147',\n",
    "             'https://weibo.com/xhstyb?refer_flag=1001030103_',\n",
    "             'https://weibo.com/cctvnewsbeijing?ssl_rnd=1625044839.2109&is_all=1',\n",
    "             'https://weibo.com/u/3704995720?refer_flag=1001030103_',\n",
    "             'https://weibo.com/badnewscn?nick=%E4%B8%8A%E6%B5%B7%E4%B9%90%E6%A2%A6_Bad_News_China',\n",
    "             'https://weibo.com/chinadailywebsite?ssl_rnd=1623648346.4715',\n",
    "             'https://weibo.com/chinadailywebsite?ssl_rnd=1623648346.4715&is_all=1',\n",
    "             'https://weibo.com/weather01?refer_flag=1001030103_',\n",
    "             'https://weibo.com/cctvnewsbeijing?refer_flag=1001030103_',\n",
    "             'https://weibo.com/cctvnewsbeijing?refer_flag=1001030103_&ssl_rnd=1623648683.3943&is_all=1',\n",
    "             'https://weibo.com/baincompany?refer_flag=1001030103_&ssl_rnd=1623649023.9775&is_all=1',\n",
    "             'https://weibo.com/u/6139776919?refer_flag=1001030103_',\n",
    "             'https://weibo.com/ttarticle/p/show?id=2309404621567283036299',\n",
    "             'https://weibo.com/zhongguowang?refer_flag=1001030103_',\n",
    "             'https://weibo.com/chinadailywebsite?ssl_rnd=1623648346.4715&is_all=1',\n",
    "             'https://weibo.com/cctv5?ssl_rnd=1625045238.3648&is_all=1',\n",
    "             'https://weibo.com/cgtnenespanol?refer_flag=1001030103_',\n",
    "             'https://weibo.com/chinanewsv?ssl_rnd=1625045298.6861',\n",
    "             'https://weibo.com/cctvnewsbeijing?refer_flag=1001030103_&is_all=1',\n",
    "             'https://weibo.com/cctvnewsbeijing?refer_flag=1001030103_&ssl_rnd=1623650973.4547&is_all=1',\n",
    "             'https://weibo.com/cctvnewsbeijing?refer_flag=1001030103_&ssl_rnd=1623650973.4547&is_all=1',\n",
    "             'https://weibo.com/gxrb2013?refer_flag=1001030103_&ssl_rnd=1623654240.3591',\n",
    "             'https://weibo.com/gmrb1949?ssl_rnd=1623654193.1401s',\n",
    "             'https://weibo.com/beijingdaily?ssl_rnd=1625045336.662',\n",
    "             'https://weibo.com/thepapernewsapp?nick=%E6%BE%8E%E6%B9%83%E6%96%B0%E9%97%BB',\n",
    "             'https://s.weibo.com/claim/apply?object_id=1022:231522de583bd8b6ab3e27312f5d2d87d081ea&uid=0&query=%23%E7%8E%AF%E7%90%83%E6%97%B6%E6%8A%A5%23',\n",
    "             'https://weibo.com/u/6314326330?ssl_rnd=1625045361.6221',\n",
    "             'https://weibo.com/shinebridal?is_all=1']\n",
    "\n",
    "foot_fall = c.get_foot_fall(publish_source)\n",
    "\n",
    "for user_link in user_links:\n",
    "    if '&ssl_rnd' not in user_link:\n",
    "        user_link += '&ssl_rnd=1625039615.9147'\n",
    "    logger.info(f'Fetching cat url  {user_link}\\n') \n",
    "    try:\n",
    "        user_page = requests.get(user_link,headers = headers ,timeout=200).text\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        print(\"time error\")\n",
    "    if user_page.startswith('Unable to fetch'):\n",
    "        logger.info(user_page) # writes error message with error code\n",
    "        no_of_not_working_queries += 1\n",
    "        continue   \n",
    "    \n",
    "    for i in user_page.split('WB_feed_detail clearfix')[1:]:\n",
    "        # Date and time \n",
    "        date_time = c.scrap('<a\\s*name=.*?title=.*?\"(.*?)\"', i) \n",
    "        date_time  = re.sub(r'\\\\','',date_time)  \n",
    "        date_time = c.strip_html(date_time)\n",
    "\n",
    "        source_content = c.scrap('<div\\s*class=.*?\"WB_text W_f14.*?\".*?>(.*?)<div.*?class=.*?\"WB_expand_media_box', i)\n",
    "        if not source_content:\n",
    "            source_content = c.scrap('<div\\s*class=.*?\"WB_text W_f14.*?\".*?>(.*?)<a\\s*suda-uatrack=', i) + '\\n' + date_time\n",
    "        source_content = c.strip_html(source_content)\n",
    "        source_content = re.sub(r'\\\\n','',source_content,re.S)  \n",
    "        source_content = re.sub(r'\\\\','',source_content,re.S)\n",
    "       \n",
    "\n",
    "        # skip if content not found\n",
    "        if not source_content:\n",
    "            logger.info(f'Skipping due to content {user_link}\\n')\n",
    "            skipped_due_to_content += 1\n",
    "            continue\n",
    "        # handle duplicates\n",
    "        content_query = {'content':source_content}\n",
    "        dic = cl_data.find_one(content_query,{'content': 1}) \n",
    "        if dic:\n",
    "            duplicate_data += 1\n",
    "            continue\n",
    "\n",
    "#         # source_headline\n",
    "        source_headline = source_content\n",
    "    \n",
    "#        user name\n",
    "        username = c.scrap('nick=(.*?)\\&', i)\n",
    "\n",
    "        # skip if username not found\n",
    "        if not username:\n",
    "            logger.info(f'Skipping due to username {user_link}\\n')\n",
    "            skipped_due_to_username += 1\n",
    "            continue  \n",
    "#       # journalist\n",
    "        journalist = ''\n",
    "        if not journalist: journalist = 'NA'\n",
    "\n",
    "        # current date and time \n",
    "        harvest_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "        # headline and content \n",
    "        headline = source_headline\n",
    "        content = source_content\n",
    "\n",
    "        # overall_tonality\n",
    "        overall_tonality = ''\n",
    "\n",
    "        # word count\n",
    "        word_count = len((source_headline + ' ' + source_content).split())\n",
    "\n",
    "        html_content = ''\n",
    "\n",
    "        # image_urls\n",
    "        image_urls = []\n",
    "        images_path = []\n",
    "        \n",
    "        favourites = c.scrap('click:fav\">.*?>(.*?)<', i)\n",
    "        favourites = c.scrap('(\\d+)', favourites)\n",
    "        \n",
    "        forward = c.scrap('click:repost.*?>(.*?)<', i)\n",
    "        forward = c.scrap('(\\d+)', forward)\n",
    "        \n",
    "        comments = c.scrap('click:comment.*?>(.*?)<', i)\n",
    "        comments = c.scrap('(\\d+)', comments)        \n",
    "        \n",
    "        likes = c.scrap('click:like.*?<em>(.*?)</em>', i)\n",
    "        likes = c.scrap('(\\d+)', likes)\n",
    "        \n",
    "        # Image\n",
    "        img_urls = re.findall('<li.*?<img\\s*src=.*?\"(.*?)\"', i, flags=re.S)\n",
    "\n",
    "        for img_url in img_urls:\n",
    "            if ('admin' in img_url) or ('feed_icon_biyemao' in img_url):\n",
    "                continue\n",
    "            img_url  = re.sub(r'\\\\','',img_url)\n",
    "            img_name = c.scrap('.*/(.*)', img_url)\n",
    "            img_url  = re.sub(r'\\\\','',img_url)\n",
    "            img_path = f'{image_directory}/{img_name}'\n",
    "            if not img_url.startswith('http'):\n",
    "                img_url = 'https:' + img_url\n",
    "           \n",
    "            # if image is not downloaded return an error message\n",
    "            download_message = download_image(img_url, img_path)  \n",
    "            images_path.append(img_path)\n",
    "            \n",
    "            if download_message:\n",
    "                logger.info(download_message)  # writes error message with error code\n",
    "                unable_to_download_image += 1\n",
    "                continue  \n",
    "     \n",
    "         # storing the above data in a dictionary\n",
    "        clientdata = {\n",
    "                        \"client_master\": client_id,\n",
    "                        \"articleid\": client_id,\n",
    "                        \"medium\": \"Weibo\",\n",
    "#                         \"searchkeyword\": [query], \n",
    "                        \"entityname\": [], \n",
    "                        \"process_flage\": \"1\",\n",
    "                        \"na_flage\": \"0\",\n",
    "                        \"na_reason\": \"\",\n",
    "                        \"qc_by\": \"\",\n",
    "                        \"qc_on\": \"\",\n",
    "                        \"location\": \"\",\n",
    "                        \"spokeperson\": \"\",\n",
    "                        \"quota\": \"\",\n",
    "                        \"overall_topics\": \"\",\n",
    "                        \"person\": \"\",\n",
    "                        \"overall_entites\": \"\",\n",
    "                        \"overall_tonality\": \"\",\n",
    "                        \"overall_wordcount\": word_count,\n",
    "                        \"article_subjectivity\": \"\",\n",
    "                        \"article_summary\": \"\",\n",
    "                        \"pub_date\": pub_date,\n",
    "                        \"publish_time\": publish_time,\n",
    "                        \"harvest_time\": harvest_time,  \n",
    "                        \"temp_link\": user_link,\n",
    "                        \"publish_source\": username,  \n",
    "                        \"programme\": \"null\",\n",
    "                        \"feed_class\": \"\",\n",
    "                        \"publishing_platform\": \"Weibo\",\n",
    "                        \"klout_score\": \"0\",\n",
    "                        \"journalist\": \"\", \n",
    "                        \"headline\": source_content,  \n",
    "                        \"content\": source_content,  \n",
    "                        \"language\": language,\n",
    "                        \"location_mention\": \"\",\n",
    "                        \"source_link\":user_link,\n",
    "                        \"author_contact\": \"\",\n",
    "                        \"author_emailid\": \"\",\n",
    "                        \"author_url\": \"\",\n",
    "                        \"city\": \"\",\n",
    "                        \"state\": \"\",\n",
    "                        \"country\": country,\n",
    "                        \"source\": username,\n",
    "                        \"foot_fall\": \"\",\n",
    "                        \"created_on\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                        \"active\": \"1\",\n",
    "                        \"circulation\": \"0\",\n",
    "                        'favourites':favourites,\n",
    "                        'forward': forward,\n",
    "                        'comments':comments,\n",
    "                        'likes': likes,\n",
    "                        'images_path': images_path\n",
    "        }\n",
    "\n",
    "        cl_data.insert_one(clientdata)  \n",
    "        no_of_data += 1\n",
    "        \n",
    "\n",
    "logger.info('Iteration complete\\n')   \n",
    "logger.info(f'Number of data: {no_of_data}\\n')\n",
    "# logger.info(f'Total number of queries: {len(queries)}\\n')\n",
    "logger.info(f'No. of not working queries: {no_of_not_working_queries}\\n')\n",
    "logger.info(f'Duplicate data: {duplicate_data}\\n')\n",
    "logger.info(f'Skipped due to username: {skipped_due_to_username}\\n')\n",
    "logger.info(f'Skipped due to content: {skipped_due_to_content}\\n')\n",
    "logger.info(f'Unable to download image: {unable_to_download_image}\\n')\n",
    "logger.info(f'country: {country}\\n')\n",
    "logger.info(f'language: {language}\\n')\n",
    "logger.info(f'Processing finished in {time.time() - start_time} seconds.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-telling",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
